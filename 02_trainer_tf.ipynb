{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify data paths\n",
    "dataset = 'out/gestures.csv'\n",
    "model_save_path = 'models/classifier.hdf5'\n",
    "tflite_save_path = 'models/lite.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "machedici      447\n",
       "one_up         414\n",
       "hand_closed    410\n",
       "random         407\n",
       "two_up         387\n",
       "hand_open      339\n",
       "victory        310\n",
       "hang_in        310\n",
       "call           284\n",
       "ok             215\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(dataset, header=None) \n",
    "\n",
    "y = data.iloc[:, 0]\n",
    "X = data.iloc[: , 1:]\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = y.unique()\n",
    "classes = {classes[i]: i for i in range(len(classes))}\n",
    "\n",
    "y = y.map(classes)\n",
    "\n",
    "X = X.to_numpy().astype(np.float32)\n",
    "y = y.to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=RANDOM_SEED)\n",
    "\n",
    "# # y_train = y_train.reshape(len(y_train),1)\n",
    "# # y_test = y_test.reshape(len(y_test),1)\n",
    "# classes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 19:28:06.366911: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-23 19:28:06.367954: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "n_input = X_train.shape[1]\n",
    "n_output = len(np.unique(y))\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer((n_input, )),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(n_output, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1376      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 3,130\n",
      "Trainable params: 3,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False, save_best_only=True)\n",
    "# Callback for early stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=50, verbose=1)\n",
    "\n",
    "# Model compilation\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 19:28:17.386213: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-07-23 19:28:17.389960: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 19:28:17.683942: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 21ms/step - loss: 2.2946 - accuracy: 0.1151 - val_loss: 2.2866 - val_accuracy: 0.1169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 19:28:19.657185: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.28659, saving model to models/classifier.hdf5\n",
      "Epoch 2/1000\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 2.2650 - accuracy: 0.1431 - val_loss: 2.2736 - val_accuracy: 0.1169\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.28659 to 2.27364, saving model to models/classifier.hdf5\n",
      "Epoch 3/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 2.2382 - accuracy: 0.1927 - val_loss: 2.2565 - val_accuracy: 0.1169\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.27364 to 2.25648, saving model to models/classifier.hdf5\n",
      "Epoch 4/1000\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 2.2024 - accuracy: 0.2051 - val_loss: 2.1896 - val_accuracy: 0.2043\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.25648 to 2.18961, saving model to models/classifier.hdf5\n",
      "Epoch 5/1000\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 2.1352 - accuracy: 0.2373 - val_loss: 2.0937 - val_accuracy: 0.2157\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.18961 to 2.09368, saving model to models/classifier.hdf5\n",
      "Epoch 6/1000\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 2.0433 - accuracy: 0.2752 - val_loss: 1.9593 - val_accuracy: 0.3087\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.09368 to 1.95934, saving model to models/classifier.hdf5\n",
      "Epoch 7/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.9427 - accuracy: 0.3085 - val_loss: 1.8000 - val_accuracy: 0.3405\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.95934 to 1.80003, saving model to models/classifier.hdf5\n",
      "Epoch 8/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1.8297 - accuracy: 0.3524 - val_loss: 1.6494 - val_accuracy: 0.5539\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.80003 to 1.64944, saving model to models/classifier.hdf5\n",
      "Epoch 9/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1.7082 - accuracy: 0.4035 - val_loss: 1.5194 - val_accuracy: 0.5698\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.64944 to 1.51940, saving model to models/classifier.hdf5\n",
      "Epoch 10/1000\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.6036 - accuracy: 0.4451 - val_loss: 1.3921 - val_accuracy: 0.6402\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.51940 to 1.39210, saving model to models/classifier.hdf5\n",
      "Epoch 11/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 1.5167 - accuracy: 0.4769 - val_loss: 1.2835 - val_accuracy: 0.6640\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.39210 to 1.28351, saving model to models/classifier.hdf5\n",
      "Epoch 12/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1.4229 - accuracy: 0.5121 - val_loss: 1.1968 - val_accuracy: 0.6640\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.28351 to 1.19679, saving model to models/classifier.hdf5\n",
      "Epoch 13/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 1.3775 - accuracy: 0.4992 - val_loss: 1.1286 - val_accuracy: 0.6935\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.19679 to 1.12864, saving model to models/classifier.hdf5\n",
      "Epoch 14/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1.3063 - accuracy: 0.5291 - val_loss: 1.0707 - val_accuracy: 0.6697\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.12864 to 1.07066, saving model to models/classifier.hdf5\n",
      "Epoch 15/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 1.2530 - accuracy: 0.5496 - val_loss: 1.0207 - val_accuracy: 0.6867\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.07066 to 1.02067, saving model to models/classifier.hdf5\n",
      "Epoch 16/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 1.2059 - accuracy: 0.5632 - val_loss: 0.9864 - val_accuracy: 0.6640\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.02067 to 0.98641, saving model to models/classifier.hdf5\n",
      "Epoch 17/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1.1623 - accuracy: 0.5723 - val_loss: 0.9405 - val_accuracy: 0.6788\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.98641 to 0.94047, saving model to models/classifier.hdf5\n",
      "Epoch 18/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1.1129 - accuracy: 0.5810 - val_loss: 0.9063 - val_accuracy: 0.6799\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.94047 to 0.90632, saving model to models/classifier.hdf5\n",
      "Epoch 19/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1.0782 - accuracy: 0.6037 - val_loss: 0.8801 - val_accuracy: 0.6754\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.90632 to 0.88009, saving model to models/classifier.hdf5\n",
      "Epoch 20/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1.0440 - accuracy: 0.6041 - val_loss: 0.8496 - val_accuracy: 0.6799\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.88009 to 0.84958, saving model to models/classifier.hdf5\n",
      "Epoch 21/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 1.0347 - accuracy: 0.6003 - val_loss: 0.8392 - val_accuracy: 0.6890\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.84958 to 0.83924, saving model to models/classifier.hdf5\n",
      "Epoch 22/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 1.0120 - accuracy: 0.6128 - val_loss: 0.8292 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.83924 to 0.82919, saving model to models/classifier.hdf5\n",
      "Epoch 23/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.9645 - accuracy: 0.6245 - val_loss: 0.7899 - val_accuracy: 0.6901\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.82919 to 0.78989, saving model to models/classifier.hdf5\n",
      "Epoch 24/1000\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.9320 - accuracy: 0.6491 - val_loss: 0.7768 - val_accuracy: 0.6822\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.78989 to 0.77684, saving model to models/classifier.hdf5\n",
      "Epoch 25/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.9093 - accuracy: 0.6442 - val_loss: 0.7536 - val_accuracy: 0.6969\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.77684 to 0.75361, saving model to models/classifier.hdf5\n",
      "Epoch 26/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.9006 - accuracy: 0.6438 - val_loss: 0.7687 - val_accuracy: 0.6788\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.75361\n",
      "Epoch 27/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8730 - accuracy: 0.6510 - val_loss: 0.7540 - val_accuracy: 0.6742\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.75361\n",
      "Epoch 28/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.8637 - accuracy: 0.6635 - val_loss: 0.7386 - val_accuracy: 0.6663\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.75361 to 0.73860, saving model to models/classifier.hdf5\n",
      "Epoch 29/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.8443 - accuracy: 0.6609 - val_loss: 0.7001 - val_accuracy: 0.7140\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.73860 to 0.70012, saving model to models/classifier.hdf5\n",
      "Epoch 30/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.8398 - accuracy: 0.6646 - val_loss: 0.6978 - val_accuracy: 0.7003\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.70012 to 0.69783, saving model to models/classifier.hdf5\n",
      "Epoch 31/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.8067 - accuracy: 0.6802 - val_loss: 0.6992 - val_accuracy: 0.6879\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.69783\n",
      "Epoch 32/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.7949 - accuracy: 0.6843 - val_loss: 0.6864 - val_accuracy: 0.6913\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.69783 to 0.68641, saving model to models/classifier.hdf5\n",
      "Epoch 33/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.7744 - accuracy: 0.6949 - val_loss: 0.6744 - val_accuracy: 0.6935\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.68641 to 0.67441, saving model to models/classifier.hdf5\n",
      "Epoch 34/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 0.7784 - accuracy: 0.6847 - val_loss: 0.6910 - val_accuracy: 0.6958\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.67441\n",
      "Epoch 35/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7695 - accuracy: 0.6885 - val_loss: 0.6867 - val_accuracy: 0.7094\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.67441\n",
      "Epoch 36/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.7519 - accuracy: 0.6991 - val_loss: 0.7130 - val_accuracy: 0.6992\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.67441\n",
      "Epoch 37/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.7497 - accuracy: 0.7010 - val_loss: 0.6978 - val_accuracy: 0.7208\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.67441\n",
      "Epoch 38/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.7396 - accuracy: 0.7067 - val_loss: 0.6547 - val_accuracy: 0.7310\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.67441 to 0.65473, saving model to models/classifier.hdf5\n",
      "Epoch 39/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.7287 - accuracy: 0.7067 - val_loss: 0.6449 - val_accuracy: 0.7117\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.65473 to 0.64490, saving model to models/classifier.hdf5\n",
      "Epoch 40/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7161 - accuracy: 0.7082 - val_loss: 0.6550 - val_accuracy: 0.7287\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.64490\n",
      "Epoch 41/1000\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.7103 - accuracy: 0.7139 - val_loss: 0.6500 - val_accuracy: 0.7162\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.64490\n",
      "Epoch 42/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.7068 - accuracy: 0.7108 - val_loss: 0.6560 - val_accuracy: 0.7117\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.64490\n",
      "Epoch 43/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 0.7189 - accuracy: 0.7055 - val_loss: 0.6403 - val_accuracy: 0.7287\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.64490 to 0.64027, saving model to models/classifier.hdf5\n",
      "Epoch 44/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.6932 - accuracy: 0.7218 - val_loss: 0.6326 - val_accuracy: 0.7378\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.64027 to 0.63257, saving model to models/classifier.hdf5\n",
      "Epoch 45/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 0.6873 - accuracy: 0.7245 - val_loss: 0.6295 - val_accuracy: 0.7446\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.63257 to 0.62948, saving model to models/classifier.hdf5\n",
      "Epoch 46/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.6757 - accuracy: 0.7226 - val_loss: 0.6221 - val_accuracy: 0.7480\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.62948 to 0.62213, saving model to models/classifier.hdf5\n",
      "Epoch 47/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.6890 - accuracy: 0.7245 - val_loss: 0.6180 - val_accuracy: 0.7355\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.62213 to 0.61801, saving model to models/classifier.hdf5\n",
      "Epoch 48/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.6694 - accuracy: 0.7267 - val_loss: 0.6087 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.61801 to 0.60870, saving model to models/classifier.hdf5\n",
      "Epoch 49/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.6685 - accuracy: 0.7245 - val_loss: 0.6149 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.60870\n",
      "Epoch 50/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.6589 - accuracy: 0.7328 - val_loss: 0.6506 - val_accuracy: 0.7321\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.60870\n",
      "Epoch 51/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6551 - accuracy: 0.7256 - val_loss: 0.6264 - val_accuracy: 0.7514\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.60870\n",
      "Epoch 52/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.6559 - accuracy: 0.7369 - val_loss: 0.5990 - val_accuracy: 0.7333\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.60870 to 0.59904, saving model to models/classifier.hdf5\n",
      "Epoch 53/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.6607 - accuracy: 0.7294 - val_loss: 0.6193 - val_accuracy: 0.7412\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.59904\n",
      "Epoch 54/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.6482 - accuracy: 0.7252 - val_loss: 0.5878 - val_accuracy: 0.7435\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.59904 to 0.58781, saving model to models/classifier.hdf5\n",
      "Epoch 55/1000\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.6486 - accuracy: 0.7472 - val_loss: 0.5948 - val_accuracy: 0.7537\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.58781\n",
      "Epoch 56/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.6400 - accuracy: 0.7422 - val_loss: 0.5970 - val_accuracy: 0.7548\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.58781\n",
      "Epoch 57/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.6276 - accuracy: 0.7506 - val_loss: 0.6106 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.58781\n",
      "Epoch 58/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.6230 - accuracy: 0.7498 - val_loss: 0.5883 - val_accuracy: 0.7469\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.58781\n",
      "Epoch 59/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.6215 - accuracy: 0.7464 - val_loss: 0.5843 - val_accuracy: 0.7650\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.58781 to 0.58427, saving model to models/classifier.hdf5\n",
      "Epoch 60/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.6209 - accuracy: 0.7381 - val_loss: 0.6103 - val_accuracy: 0.7594\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.58427\n",
      "Epoch 61/1000\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.6148 - accuracy: 0.7449 - val_loss: 0.5854 - val_accuracy: 0.7616\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.58427\n",
      "Epoch 62/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6095 - accuracy: 0.7540 - val_loss: 0.5907 - val_accuracy: 0.7491\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.58427\n",
      "Epoch 63/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.5918 - accuracy: 0.7631 - val_loss: 0.5713 - val_accuracy: 0.7526\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.58427 to 0.57127, saving model to models/classifier.hdf5\n",
      "Epoch 64/1000\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.6073 - accuracy: 0.7494 - val_loss: 0.5740 - val_accuracy: 0.7696\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.57127\n",
      "Epoch 65/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 0.6179 - accuracy: 0.7536 - val_loss: 0.6459 - val_accuracy: 0.7344\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.57127\n",
      "Epoch 66/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.6029 - accuracy: 0.7627 - val_loss: 0.5779 - val_accuracy: 0.7639\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.57127\n",
      "Epoch 67/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.5901 - accuracy: 0.7619 - val_loss: 0.5728 - val_accuracy: 0.7560\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.57127\n",
      "Epoch 68/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.5927 - accuracy: 0.7536 - val_loss: 0.5547 - val_accuracy: 0.7435\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.57127 to 0.55468, saving model to models/classifier.hdf5\n",
      "Epoch 69/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.5857 - accuracy: 0.7733 - val_loss: 0.6336 - val_accuracy: 0.7321\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.55468\n",
      "Epoch 70/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.5926 - accuracy: 0.7619 - val_loss: 0.5744 - val_accuracy: 0.7548\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.55468\n",
      "Epoch 71/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.5691 - accuracy: 0.7706 - val_loss: 0.5674 - val_accuracy: 0.7639\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.55468\n",
      "Epoch 72/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.5739 - accuracy: 0.7646 - val_loss: 0.5618 - val_accuracy: 0.7650\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.55468\n",
      "Epoch 73/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.5827 - accuracy: 0.7619 - val_loss: 0.5544 - val_accuracy: 0.7764\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.55468 to 0.55436, saving model to models/classifier.hdf5\n",
      "Epoch 74/1000\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.5724 - accuracy: 0.7763 - val_loss: 0.5619 - val_accuracy: 0.7662\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.55436\n",
      "Epoch 75/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.5670 - accuracy: 0.7672 - val_loss: 0.5691 - val_accuracy: 0.7775\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.55436\n",
      "Epoch 76/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.5570 - accuracy: 0.7786 - val_loss: 0.5533 - val_accuracy: 0.7594\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.55436 to 0.55331, saving model to models/classifier.hdf5\n",
      "Epoch 77/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.5617 - accuracy: 0.7774 - val_loss: 0.5351 - val_accuracy: 0.7753\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.55331 to 0.53514, saving model to models/classifier.hdf5\n",
      "Epoch 78/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.5628 - accuracy: 0.7786 - val_loss: 0.5731 - val_accuracy: 0.7673\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.53514\n",
      "Epoch 79/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.5621 - accuracy: 0.7718 - val_loss: 0.5420 - val_accuracy: 0.7673\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.53514\n",
      "Epoch 80/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.5430 - accuracy: 0.7858 - val_loss: 0.5305 - val_accuracy: 0.7764\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.53514 to 0.53046, saving model to models/classifier.hdf5\n",
      "Epoch 81/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.5436 - accuracy: 0.7797 - val_loss: 0.5348 - val_accuracy: 0.7809\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.53046\n",
      "Epoch 82/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.5466 - accuracy: 0.7740 - val_loss: 0.5348 - val_accuracy: 0.7707\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.53046\n",
      "Epoch 83/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.5470 - accuracy: 0.7816 - val_loss: 0.5254 - val_accuracy: 0.7753\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.53046 to 0.52535, saving model to models/classifier.hdf5\n",
      "Epoch 84/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 0.5449 - accuracy: 0.7873 - val_loss: 0.5383 - val_accuracy: 0.7707\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.52535\n",
      "Epoch 85/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.5462 - accuracy: 0.7846 - val_loss: 0.5337 - val_accuracy: 0.7877\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.52535\n",
      "Epoch 86/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.5259 - accuracy: 0.7967 - val_loss: 0.5184 - val_accuracy: 0.7753\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.52535 to 0.51844, saving model to models/classifier.hdf5\n",
      "Epoch 87/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.5221 - accuracy: 0.7858 - val_loss: 0.5068 - val_accuracy: 0.7866\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.51844 to 0.50683, saving model to models/classifier.hdf5\n",
      "Epoch 88/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.5320 - accuracy: 0.7843 - val_loss: 0.5088 - val_accuracy: 0.7911\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.50683\n",
      "Epoch 89/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.5391 - accuracy: 0.7827 - val_loss: 0.5173 - val_accuracy: 0.7866\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.50683\n",
      "Epoch 90/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.5281 - accuracy: 0.7892 - val_loss: 0.5389 - val_accuracy: 0.7821\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.50683\n",
      "Epoch 91/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.5251 - accuracy: 0.7922 - val_loss: 0.5195 - val_accuracy: 0.7889\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.50683\n",
      "Epoch 92/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.5256 - accuracy: 0.7888 - val_loss: 0.5124 - val_accuracy: 0.7889\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.50683\n",
      "Epoch 93/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.5351 - accuracy: 0.7903 - val_loss: 0.4986 - val_accuracy: 0.7855\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.50683 to 0.49859, saving model to models/classifier.hdf5\n",
      "Epoch 94/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.5250 - accuracy: 0.7854 - val_loss: 0.5040 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.49859\n",
      "Epoch 95/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.5189 - accuracy: 0.7918 - val_loss: 0.5087 - val_accuracy: 0.7923\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.49859\n",
      "Epoch 96/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.5108 - accuracy: 0.7960 - val_loss: 0.5670 - val_accuracy: 0.7719\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.49859\n",
      "Epoch 97/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.5295 - accuracy: 0.7922 - val_loss: 0.5083 - val_accuracy: 0.7911\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.49859\n",
      "Epoch 98/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.5107 - accuracy: 0.7998 - val_loss: 0.4905 - val_accuracy: 0.7877\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.49859 to 0.49046, saving model to models/classifier.hdf5\n",
      "Epoch 99/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.5015 - accuracy: 0.8051 - val_loss: 0.5102 - val_accuracy: 0.8048\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.49046\n",
      "Epoch 100/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.5083 - accuracy: 0.7986 - val_loss: 0.4880 - val_accuracy: 0.7946\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.49046 to 0.48802, saving model to models/classifier.hdf5\n",
      "Epoch 101/1000\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.5199 - accuracy: 0.8013 - val_loss: 0.5459 - val_accuracy: 0.7991\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.48802\n",
      "Epoch 102/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 0.5021 - accuracy: 0.7918 - val_loss: 0.4885 - val_accuracy: 0.8002\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.48802\n",
      "Epoch 103/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 0.4978 - accuracy: 0.8013 - val_loss: 0.4789 - val_accuracy: 0.7946\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.48802 to 0.47891, saving model to models/classifier.hdf5\n",
      "Epoch 104/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 0.5014 - accuracy: 0.8047 - val_loss: 0.4976 - val_accuracy: 0.7957\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.47891\n",
      "Epoch 105/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.5150 - accuracy: 0.7911 - val_loss: 0.4902 - val_accuracy: 0.7832\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.47891\n",
      "Epoch 106/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4983 - accuracy: 0.8070 - val_loss: 0.4800 - val_accuracy: 0.8025\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.47891\n",
      "Epoch 107/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.4999 - accuracy: 0.8017 - val_loss: 0.4853 - val_accuracy: 0.8036\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.47891\n",
      "Epoch 108/1000\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.4960 - accuracy: 0.8107 - val_loss: 0.5052 - val_accuracy: 0.8116\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.47891\n",
      "Epoch 109/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4964 - accuracy: 0.8092 - val_loss: 0.4817 - val_accuracy: 0.7968\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.47891\n",
      "Epoch 110/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.4881 - accuracy: 0.8111 - val_loss: 0.4729 - val_accuracy: 0.8002\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.47891 to 0.47294, saving model to models/classifier.hdf5\n",
      "Epoch 111/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.4851 - accuracy: 0.8081 - val_loss: 0.4700 - val_accuracy: 0.8048\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.47294 to 0.46997, saving model to models/classifier.hdf5\n",
      "Epoch 112/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.4927 - accuracy: 0.8104 - val_loss: 0.4799 - val_accuracy: 0.8025\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.46997\n",
      "Epoch 113/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4849 - accuracy: 0.8138 - val_loss: 0.4636 - val_accuracy: 0.8150\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.46997 to 0.46362, saving model to models/classifier.hdf5\n",
      "Epoch 114/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.4914 - accuracy: 0.8043 - val_loss: 0.4729 - val_accuracy: 0.8116\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.46362\n",
      "Epoch 115/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.4919 - accuracy: 0.8089 - val_loss: 0.4757 - val_accuracy: 0.8127\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.46362\n",
      "Epoch 116/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4895 - accuracy: 0.8062 - val_loss: 0.4589 - val_accuracy: 0.8161\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.46362 to 0.45888, saving model to models/classifier.hdf5\n",
      "Epoch 117/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.4818 - accuracy: 0.8145 - val_loss: 0.4615 - val_accuracy: 0.8104\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.45888\n",
      "Epoch 118/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.4662 - accuracy: 0.8255 - val_loss: 0.4778 - val_accuracy: 0.7946\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.45888\n",
      "Epoch 119/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.4717 - accuracy: 0.8134 - val_loss: 0.4595 - val_accuracy: 0.8036\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.45888\n",
      "Epoch 120/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4771 - accuracy: 0.8236 - val_loss: 0.4693 - val_accuracy: 0.8150\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.45888\n",
      "Epoch 121/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4708 - accuracy: 0.8232 - val_loss: 0.4620 - val_accuracy: 0.8104\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.45888\n",
      "Epoch 122/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.4772 - accuracy: 0.8164 - val_loss: 0.4776 - val_accuracy: 0.8025\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.45888\n",
      "Epoch 123/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.4740 - accuracy: 0.8111 - val_loss: 0.4623 - val_accuracy: 0.8104\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.45888\n",
      "Epoch 124/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4766 - accuracy: 0.8172 - val_loss: 0.4513 - val_accuracy: 0.8229\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.45888 to 0.45135, saving model to models/classifier.hdf5\n",
      "Epoch 125/1000\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.4668 - accuracy: 0.8217 - val_loss: 0.4577 - val_accuracy: 0.8093\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.45135\n",
      "Epoch 126/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4831 - accuracy: 0.8089 - val_loss: 0.4859 - val_accuracy: 0.8116\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.45135\n",
      "Epoch 127/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4675 - accuracy: 0.8179 - val_loss: 0.4588 - val_accuracy: 0.8161\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.45135\n",
      "Epoch 128/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4691 - accuracy: 0.8157 - val_loss: 0.4733 - val_accuracy: 0.8150\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.45135\n",
      "Epoch 129/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.4565 - accuracy: 0.8210 - val_loss: 0.4574 - val_accuracy: 0.8025\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.45135\n",
      "Epoch 130/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4779 - accuracy: 0.8251 - val_loss: 0.4488 - val_accuracy: 0.8184\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.45135 to 0.44883, saving model to models/classifier.hdf5\n",
      "Epoch 131/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4475 - accuracy: 0.8316 - val_loss: 0.4667 - val_accuracy: 0.8150\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.44883\n",
      "Epoch 132/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.4574 - accuracy: 0.8297 - val_loss: 0.4346 - val_accuracy: 0.8263\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.44883 to 0.43456, saving model to models/classifier.hdf5\n",
      "Epoch 133/1000\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.4595 - accuracy: 0.8274 - val_loss: 0.4318 - val_accuracy: 0.8241\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.43456 to 0.43185, saving model to models/classifier.hdf5\n",
      "Epoch 134/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.4516 - accuracy: 0.8285 - val_loss: 0.4330 - val_accuracy: 0.8070\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.43185\n",
      "Epoch 135/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4457 - accuracy: 0.8236 - val_loss: 0.4942 - val_accuracy: 0.8093\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.43185\n",
      "Epoch 136/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4568 - accuracy: 0.8319 - val_loss: 0.4457 - val_accuracy: 0.8127\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.43185\n",
      "Epoch 137/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4346 - accuracy: 0.8327 - val_loss: 0.4726 - val_accuracy: 0.8207\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.43185\n",
      "Epoch 138/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4475 - accuracy: 0.8259 - val_loss: 0.4522 - val_accuracy: 0.8229\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.43185\n",
      "Epoch 139/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4521 - accuracy: 0.8289 - val_loss: 0.4484 - val_accuracy: 0.8184\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.43185\n",
      "Epoch 140/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4467 - accuracy: 0.8229 - val_loss: 0.4326 - val_accuracy: 0.8241\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.43185\n",
      "Epoch 141/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4435 - accuracy: 0.8206 - val_loss: 0.4677 - val_accuracy: 0.8184\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.43185\n",
      "Epoch 142/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4488 - accuracy: 0.8319 - val_loss: 0.4254 - val_accuracy: 0.8218\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.43185 to 0.42537, saving model to models/classifier.hdf5\n",
      "Epoch 143/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4421 - accuracy: 0.8316 - val_loss: 0.4270 - val_accuracy: 0.8275\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.42537\n",
      "Epoch 144/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4434 - accuracy: 0.8240 - val_loss: 0.4248 - val_accuracy: 0.8263\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.42537 to 0.42477, saving model to models/classifier.hdf5\n",
      "Epoch 145/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.4491 - accuracy: 0.8380 - val_loss: 0.4436 - val_accuracy: 0.8138\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.42477\n",
      "Epoch 146/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.4374 - accuracy: 0.8259 - val_loss: 0.4346 - val_accuracy: 0.8309\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.42477\n",
      "Epoch 147/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4490 - accuracy: 0.8297 - val_loss: 0.4260 - val_accuracy: 0.8320\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.42477\n",
      "Epoch 148/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4396 - accuracy: 0.8293 - val_loss: 0.4248 - val_accuracy: 0.8388\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.42477\n",
      "Epoch 149/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4442 - accuracy: 0.8304 - val_loss: 0.4417 - val_accuracy: 0.8173\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.42477\n",
      "Epoch 150/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.4501 - accuracy: 0.8251 - val_loss: 0.4436 - val_accuracy: 0.8173\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.42477\n",
      "Epoch 151/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4376 - accuracy: 0.8301 - val_loss: 0.4231 - val_accuracy: 0.8320\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.42477 to 0.42307, saving model to models/classifier.hdf5\n",
      "Epoch 152/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4302 - accuracy: 0.8308 - val_loss: 0.4201 - val_accuracy: 0.8479\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.42307 to 0.42011, saving model to models/classifier.hdf5\n",
      "Epoch 153/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.4373 - accuracy: 0.8316 - val_loss: 0.4157 - val_accuracy: 0.8354\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.42011 to 0.41567, saving model to models/classifier.hdf5\n",
      "Epoch 154/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.4195 - accuracy: 0.8376 - val_loss: 0.4170 - val_accuracy: 0.8388\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.41567\n",
      "Epoch 155/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4192 - accuracy: 0.8467 - val_loss: 0.4230 - val_accuracy: 0.8377\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.41567\n",
      "Epoch 156/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.4248 - accuracy: 0.8357 - val_loss: 0.4252 - val_accuracy: 0.8513\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.41567\n",
      "Epoch 157/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4425 - accuracy: 0.8263 - val_loss: 0.4193 - val_accuracy: 0.8456\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.41567\n",
      "Epoch 158/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.4296 - accuracy: 0.8357 - val_loss: 0.4059 - val_accuracy: 0.8275\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.41567 to 0.40588, saving model to models/classifier.hdf5\n",
      "Epoch 159/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.4314 - accuracy: 0.8346 - val_loss: 0.4106 - val_accuracy: 0.8411\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.40588\n",
      "Epoch 160/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4227 - accuracy: 0.8471 - val_loss: 0.4264 - val_accuracy: 0.8513\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.40588\n",
      "Epoch 161/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4328 - accuracy: 0.8425 - val_loss: 0.4058 - val_accuracy: 0.8207\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.40588 to 0.40578, saving model to models/classifier.hdf5\n",
      "Epoch 162/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.4318 - accuracy: 0.8316 - val_loss: 0.4046 - val_accuracy: 0.8570\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.40578 to 0.40462, saving model to models/classifier.hdf5\n",
      "Epoch 163/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4250 - accuracy: 0.8369 - val_loss: 0.4276 - val_accuracy: 0.8388\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.40462\n",
      "Epoch 164/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4136 - accuracy: 0.8429 - val_loss: 0.3996 - val_accuracy: 0.8536\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.40462 to 0.39960, saving model to models/classifier.hdf5\n",
      "Epoch 165/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4301 - accuracy: 0.8369 - val_loss: 0.4673 - val_accuracy: 0.8411\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.39960\n",
      "Epoch 166/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 0.4128 - accuracy: 0.8425 - val_loss: 0.4075 - val_accuracy: 0.8490\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.39960\n",
      "Epoch 167/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.4136 - accuracy: 0.8456 - val_loss: 0.4113 - val_accuracy: 0.8502\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.39960\n",
      "Epoch 168/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4133 - accuracy: 0.8467 - val_loss: 0.4018 - val_accuracy: 0.8331\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.39960\n",
      "Epoch 169/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4275 - accuracy: 0.8403 - val_loss: 0.4129 - val_accuracy: 0.8309\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.39960\n",
      "Epoch 170/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4162 - accuracy: 0.8399 - val_loss: 0.4213 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.39960\n",
      "Epoch 171/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4175 - accuracy: 0.8403 - val_loss: 0.4068 - val_accuracy: 0.8331\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.39960\n",
      "Epoch 172/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4281 - accuracy: 0.8319 - val_loss: 0.4168 - val_accuracy: 0.8411\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.39960\n",
      "Epoch 173/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4112 - accuracy: 0.8482 - val_loss: 0.4214 - val_accuracy: 0.8490\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.39960\n",
      "Epoch 174/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.4107 - accuracy: 0.8524 - val_loss: 0.4159 - val_accuracy: 0.8456\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.39960\n",
      "Epoch 175/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4190 - accuracy: 0.8384 - val_loss: 0.4009 - val_accuracy: 0.8479\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.39960\n",
      "Epoch 176/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4116 - accuracy: 0.8471 - val_loss: 0.3859 - val_accuracy: 0.8536\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.39960 to 0.38591, saving model to models/classifier.hdf5\n",
      "Epoch 177/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4082 - accuracy: 0.8471 - val_loss: 0.4166 - val_accuracy: 0.8479\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.38591\n",
      "Epoch 178/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4212 - accuracy: 0.8380 - val_loss: 0.3944 - val_accuracy: 0.8468\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.38591\n",
      "Epoch 179/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4116 - accuracy: 0.8456 - val_loss: 0.4187 - val_accuracy: 0.8456\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.38591\n",
      "Epoch 180/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4177 - accuracy: 0.8391 - val_loss: 0.4046 - val_accuracy: 0.8354\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.38591\n",
      "Epoch 181/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4196 - accuracy: 0.8342 - val_loss: 0.3985 - val_accuracy: 0.8456\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.38591\n",
      "Epoch 182/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4100 - accuracy: 0.8444 - val_loss: 0.4043 - val_accuracy: 0.8536\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.38591\n",
      "Epoch 183/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3994 - accuracy: 0.8452 - val_loss: 0.4119 - val_accuracy: 0.8524\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.38591\n",
      "Epoch 184/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.4106 - accuracy: 0.8516 - val_loss: 0.3985 - val_accuracy: 0.8434\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.38591\n",
      "Epoch 185/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4058 - accuracy: 0.8509 - val_loss: 0.4003 - val_accuracy: 0.8513\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.38591\n",
      "Epoch 186/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.4109 - accuracy: 0.8516 - val_loss: 0.3908 - val_accuracy: 0.8388\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.38591\n",
      "Epoch 187/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4018 - accuracy: 0.8512 - val_loss: 0.3833 - val_accuracy: 0.8490\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.38591 to 0.38329, saving model to models/classifier.hdf5\n",
      "Epoch 188/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4021 - accuracy: 0.8490 - val_loss: 0.3838 - val_accuracy: 0.8502\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.38329\n",
      "Epoch 189/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4095 - accuracy: 0.8478 - val_loss: 0.4157 - val_accuracy: 0.8343\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.38329\n",
      "Epoch 190/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3983 - accuracy: 0.8422 - val_loss: 0.3841 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.38329\n",
      "Epoch 191/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 0.3940 - accuracy: 0.8505 - val_loss: 0.3794 - val_accuracy: 0.8524\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.38329 to 0.37942, saving model to models/classifier.hdf5\n",
      "Epoch 192/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.4000 - accuracy: 0.8444 - val_loss: 0.3878 - val_accuracy: 0.8570\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.37942\n",
      "Epoch 193/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3963 - accuracy: 0.8437 - val_loss: 0.3766 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.37942 to 0.37657, saving model to models/classifier.hdf5\n",
      "Epoch 194/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4020 - accuracy: 0.8505 - val_loss: 0.3858 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.37657\n",
      "Epoch 195/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3906 - accuracy: 0.8460 - val_loss: 0.3900 - val_accuracy: 0.8547\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.37657\n",
      "Epoch 196/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3923 - accuracy: 0.8509 - val_loss: 0.4020 - val_accuracy: 0.8536\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.37657\n",
      "Epoch 197/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.4009 - accuracy: 0.8429 - val_loss: 0.3777 - val_accuracy: 0.8536\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.37657\n",
      "Epoch 198/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3898 - accuracy: 0.8512 - val_loss: 0.4057 - val_accuracy: 0.8456\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.37657\n",
      "Epoch 199/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3993 - accuracy: 0.8414 - val_loss: 0.3750 - val_accuracy: 0.8490\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.37657 to 0.37496, saving model to models/classifier.hdf5\n",
      "Epoch 200/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.4156 - accuracy: 0.8346 - val_loss: 0.4142 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.37496\n",
      "Epoch 201/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3969 - accuracy: 0.8463 - val_loss: 0.3993 - val_accuracy: 0.8411\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.37496\n",
      "Epoch 202/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3992 - accuracy: 0.8497 - val_loss: 0.3789 - val_accuracy: 0.8536\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.37496\n",
      "Epoch 203/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3780 - accuracy: 0.8543 - val_loss: 0.3705 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.37496 to 0.37045, saving model to models/classifier.hdf5\n",
      "Epoch 204/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3931 - accuracy: 0.8494 - val_loss: 0.3732 - val_accuracy: 0.8627\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.37045\n",
      "Epoch 205/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3971 - accuracy: 0.8531 - val_loss: 0.3769 - val_accuracy: 0.8479\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.37045\n",
      "Epoch 206/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3839 - accuracy: 0.8565 - val_loss: 0.3960 - val_accuracy: 0.8547\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.37045\n",
      "Epoch 207/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3850 - accuracy: 0.8531 - val_loss: 0.3823 - val_accuracy: 0.8388\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.37045\n",
      "Epoch 208/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3760 - accuracy: 0.8596 - val_loss: 0.3738 - val_accuracy: 0.8513\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.37045\n",
      "Epoch 209/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3788 - accuracy: 0.8505 - val_loss: 0.3727 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.37045\n",
      "Epoch 210/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3880 - accuracy: 0.8505 - val_loss: 0.4013 - val_accuracy: 0.8468\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.37045\n",
      "Epoch 211/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3938 - accuracy: 0.8478 - val_loss: 0.4045 - val_accuracy: 0.8422\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.37045\n",
      "Epoch 212/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4015 - accuracy: 0.8448 - val_loss: 0.3740 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.37045\n",
      "Epoch 213/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3950 - accuracy: 0.8482 - val_loss: 0.3717 - val_accuracy: 0.8570\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.37045\n",
      "Epoch 214/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3902 - accuracy: 0.8512 - val_loss: 0.3975 - val_accuracy: 0.8502\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.37045\n",
      "Epoch 215/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3853 - accuracy: 0.8505 - val_loss: 0.3810 - val_accuracy: 0.8593\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.37045\n",
      "Epoch 216/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.4025 - accuracy: 0.8410 - val_loss: 0.3807 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.37045\n",
      "Epoch 217/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3807 - accuracy: 0.8554 - val_loss: 0.3814 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.37045\n",
      "Epoch 218/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3878 - accuracy: 0.8554 - val_loss: 0.3566 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.37045 to 0.35656, saving model to models/classifier.hdf5\n",
      "Epoch 219/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3930 - accuracy: 0.8573 - val_loss: 0.3628 - val_accuracy: 0.8672\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.35656\n",
      "Epoch 220/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3669 - accuracy: 0.8558 - val_loss: 0.3901 - val_accuracy: 0.8490\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.35656\n",
      "Epoch 221/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3945 - accuracy: 0.8437 - val_loss: 0.3764 - val_accuracy: 0.8502\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.35656\n",
      "Epoch 222/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.3840 - accuracy: 0.8558 - val_loss: 0.3822 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.35656\n",
      "Epoch 223/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3781 - accuracy: 0.8565 - val_loss: 0.3909 - val_accuracy: 0.8570\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.35656\n",
      "Epoch 224/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3630 - accuracy: 0.8581 - val_loss: 0.3618 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.35656\n",
      "Epoch 225/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3734 - accuracy: 0.8550 - val_loss: 0.3641 - val_accuracy: 0.8593\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.35656\n",
      "Epoch 226/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3758 - accuracy: 0.8547 - val_loss: 0.3553 - val_accuracy: 0.8570\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.35656 to 0.35529, saving model to models/classifier.hdf5\n",
      "Epoch 227/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3909 - accuracy: 0.8664 - val_loss: 0.3689 - val_accuracy: 0.8570\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.35529\n",
      "Epoch 228/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3659 - accuracy: 0.8618 - val_loss: 0.3568 - val_accuracy: 0.8695\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.35529\n",
      "Epoch 229/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3611 - accuracy: 0.8630 - val_loss: 0.3839 - val_accuracy: 0.8717\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.35529\n",
      "Epoch 230/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3834 - accuracy: 0.8505 - val_loss: 0.3752 - val_accuracy: 0.8456\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.35529\n",
      "Epoch 231/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3728 - accuracy: 0.8584 - val_loss: 0.3690 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.35529\n",
      "Epoch 232/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3753 - accuracy: 0.8577 - val_loss: 0.3861 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.35529\n",
      "Epoch 233/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3772 - accuracy: 0.8486 - val_loss: 0.3658 - val_accuracy: 0.8502\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.35529\n",
      "Epoch 234/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3870 - accuracy: 0.8509 - val_loss: 0.3664 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.35529\n",
      "Epoch 235/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3852 - accuracy: 0.8482 - val_loss: 0.3810 - val_accuracy: 0.8581\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.35529\n",
      "Epoch 236/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3714 - accuracy: 0.8524 - val_loss: 0.3551 - val_accuracy: 0.8581\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.35529 to 0.35513, saving model to models/classifier.hdf5\n",
      "Epoch 237/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3771 - accuracy: 0.8562 - val_loss: 0.3797 - val_accuracy: 0.8581\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.35513\n",
      "Epoch 238/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3632 - accuracy: 0.8543 - val_loss: 0.3533 - val_accuracy: 0.8581\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.35513 to 0.35332, saving model to models/classifier.hdf5\n",
      "Epoch 239/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 0.3683 - accuracy: 0.8543 - val_loss: 0.3674 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.35332\n",
      "Epoch 240/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3770 - accuracy: 0.8581 - val_loss: 0.3827 - val_accuracy: 0.8593\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.35332\n",
      "Epoch 241/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3742 - accuracy: 0.8596 - val_loss: 0.3464 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.35332 to 0.34643, saving model to models/classifier.hdf5\n",
      "Epoch 242/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3642 - accuracy: 0.8543 - val_loss: 0.3796 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.34643\n",
      "Epoch 243/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3567 - accuracy: 0.8592 - val_loss: 0.3445 - val_accuracy: 0.8740\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.34643 to 0.34452, saving model to models/classifier.hdf5\n",
      "Epoch 244/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3620 - accuracy: 0.8645 - val_loss: 0.3578 - val_accuracy: 0.8593\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.34452\n",
      "Epoch 245/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3633 - accuracy: 0.8531 - val_loss: 0.3678 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.34452\n",
      "Epoch 246/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3687 - accuracy: 0.8653 - val_loss: 0.3961 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.34452\n",
      "Epoch 247/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3595 - accuracy: 0.8709 - val_loss: 0.3556 - val_accuracy: 0.8695\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.34452\n",
      "Epoch 248/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3648 - accuracy: 0.8660 - val_loss: 0.3440 - val_accuracy: 0.8524\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.34452 to 0.34403, saving model to models/classifier.hdf5\n",
      "Epoch 249/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3700 - accuracy: 0.8573 - val_loss: 0.3688 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.34403\n",
      "Epoch 250/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3736 - accuracy: 0.8558 - val_loss: 0.3515 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.34403\n",
      "Epoch 251/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3662 - accuracy: 0.8592 - val_loss: 0.3455 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.34403\n",
      "Epoch 252/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3676 - accuracy: 0.8588 - val_loss: 0.3561 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.34403\n",
      "Epoch 253/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.3590 - accuracy: 0.8664 - val_loss: 0.3403 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.34403 to 0.34035, saving model to models/classifier.hdf5\n",
      "Epoch 254/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3620 - accuracy: 0.8626 - val_loss: 0.3540 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.34035\n",
      "Epoch 255/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3706 - accuracy: 0.8588 - val_loss: 0.3721 - val_accuracy: 0.8547\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.34035\n",
      "Epoch 256/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3635 - accuracy: 0.8649 - val_loss: 0.3500 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.34035\n",
      "Epoch 257/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.3653 - accuracy: 0.8660 - val_loss: 0.3596 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.34035\n",
      "Epoch 258/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.3493 - accuracy: 0.8698 - val_loss: 0.3530 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.34035\n",
      "Epoch 259/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3594 - accuracy: 0.8649 - val_loss: 0.3565 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.34035\n",
      "Epoch 260/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3465 - accuracy: 0.8698 - val_loss: 0.3413 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.34035\n",
      "Epoch 261/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3696 - accuracy: 0.8702 - val_loss: 0.3408 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.34035\n",
      "Epoch 262/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 0.3645 - accuracy: 0.8596 - val_loss: 0.3499 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.34035\n",
      "Epoch 263/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3556 - accuracy: 0.8724 - val_loss: 0.3784 - val_accuracy: 0.8502\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.34035\n",
      "Epoch 264/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3595 - accuracy: 0.8600 - val_loss: 0.3441 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.34035\n",
      "Epoch 265/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3646 - accuracy: 0.8603 - val_loss: 0.3373 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00265: val_loss improved from 0.34035 to 0.33730, saving model to models/classifier.hdf5\n",
      "Epoch 266/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3660 - accuracy: 0.8550 - val_loss: 0.3565 - val_accuracy: 0.8751\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.33730\n",
      "Epoch 267/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3461 - accuracy: 0.8603 - val_loss: 0.3394 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.33730\n",
      "Epoch 268/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3476 - accuracy: 0.8675 - val_loss: 0.3324 - val_accuracy: 0.8740\n",
      "\n",
      "Epoch 00268: val_loss improved from 0.33730 to 0.33238, saving model to models/classifier.hdf5\n",
      "Epoch 269/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3545 - accuracy: 0.8687 - val_loss: 0.3308 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00269: val_loss improved from 0.33238 to 0.33077, saving model to models/classifier.hdf5\n",
      "Epoch 270/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3709 - accuracy: 0.8656 - val_loss: 0.3762 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.33077\n",
      "Epoch 271/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3523 - accuracy: 0.8649 - val_loss: 0.3425 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.33077\n",
      "Epoch 272/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3512 - accuracy: 0.8675 - val_loss: 0.3379 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.33077\n",
      "Epoch 273/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3659 - accuracy: 0.8683 - val_loss: 0.3332 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.33077\n",
      "Epoch 274/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3469 - accuracy: 0.8671 - val_loss: 0.3774 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.33077\n",
      "Epoch 275/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3484 - accuracy: 0.8706 - val_loss: 0.3730 - val_accuracy: 0.8570\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.33077\n",
      "Epoch 276/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3604 - accuracy: 0.8637 - val_loss: 0.3385 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.33077\n",
      "Epoch 277/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3604 - accuracy: 0.8690 - val_loss: 0.3292 - val_accuracy: 0.8717\n",
      "\n",
      "Epoch 00277: val_loss improved from 0.33077 to 0.32922, saving model to models/classifier.hdf5\n",
      "Epoch 278/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3394 - accuracy: 0.8713 - val_loss: 0.3301 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.32922\n",
      "Epoch 279/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3465 - accuracy: 0.8634 - val_loss: 0.3401 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.32922\n",
      "Epoch 280/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3545 - accuracy: 0.8634 - val_loss: 0.3490 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.32922\n",
      "Epoch 281/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3594 - accuracy: 0.8630 - val_loss: 0.3386 - val_accuracy: 0.8808\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.32922\n",
      "Epoch 282/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3462 - accuracy: 0.8706 - val_loss: 0.3509 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.32922\n",
      "Epoch 283/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3600 - accuracy: 0.8615 - val_loss: 0.3479 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.32922\n",
      "Epoch 284/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3473 - accuracy: 0.8573 - val_loss: 0.3491 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.32922\n",
      "Epoch 285/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3621 - accuracy: 0.8573 - val_loss: 0.3305 - val_accuracy: 0.8695\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.32922\n",
      "Epoch 286/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3465 - accuracy: 0.8706 - val_loss: 0.3372 - val_accuracy: 0.8922\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.32922\n",
      "Epoch 287/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3526 - accuracy: 0.8653 - val_loss: 0.3211 - val_accuracy: 0.8695\n",
      "\n",
      "Epoch 00287: val_loss improved from 0.32922 to 0.32105, saving model to models/classifier.hdf5\n",
      "Epoch 288/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3455 - accuracy: 0.8675 - val_loss: 0.3385 - val_accuracy: 0.8593\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.32105\n",
      "Epoch 289/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3351 - accuracy: 0.8732 - val_loss: 0.3325 - val_accuracy: 0.8627\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.32105\n",
      "Epoch 290/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3477 - accuracy: 0.8736 - val_loss: 0.3395 - val_accuracy: 0.8740\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.32105\n",
      "Epoch 291/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3533 - accuracy: 0.8607 - val_loss: 0.3346 - val_accuracy: 0.8627\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.32105\n",
      "Epoch 292/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3445 - accuracy: 0.8683 - val_loss: 0.3215 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.32105\n",
      "Epoch 293/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3408 - accuracy: 0.8759 - val_loss: 0.3323 - val_accuracy: 0.8672\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.32105\n",
      "Epoch 294/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.3409 - accuracy: 0.8671 - val_loss: 0.3404 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.32105\n",
      "Epoch 295/1000\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 0.3699 - accuracy: 0.8653 - val_loss: 0.3273 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.32105\n",
      "Epoch 296/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3415 - accuracy: 0.8743 - val_loss: 0.3766 - val_accuracy: 0.8717\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.32105\n",
      "Epoch 297/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3361 - accuracy: 0.8728 - val_loss: 0.3718 - val_accuracy: 0.8581\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.32105\n",
      "Epoch 298/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3387 - accuracy: 0.8743 - val_loss: 0.3332 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.32105\n",
      "Epoch 299/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3488 - accuracy: 0.8653 - val_loss: 0.3442 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.32105\n",
      "Epoch 300/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3311 - accuracy: 0.8842 - val_loss: 0.3244 - val_accuracy: 0.8854\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.32105\n",
      "Epoch 301/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3407 - accuracy: 0.8641 - val_loss: 0.3636 - val_accuracy: 0.8502\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.32105\n",
      "Epoch 302/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3483 - accuracy: 0.8736 - val_loss: 0.3410 - val_accuracy: 0.8751\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.32105\n",
      "Epoch 303/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3503 - accuracy: 0.8702 - val_loss: 0.3155 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00303: val_loss improved from 0.32105 to 0.31547, saving model to models/classifier.hdf5\n",
      "Epoch 304/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3361 - accuracy: 0.8736 - val_loss: 0.3250 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.31547\n",
      "Epoch 305/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.3438 - accuracy: 0.8687 - val_loss: 0.3175 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.31547\n",
      "Epoch 306/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3418 - accuracy: 0.8717 - val_loss: 0.3360 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.31547\n",
      "Epoch 307/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3415 - accuracy: 0.8683 - val_loss: 0.3517 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.31547\n",
      "Epoch 308/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3416 - accuracy: 0.8762 - val_loss: 0.3125 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00308: val_loss improved from 0.31547 to 0.31246, saving model to models/classifier.hdf5\n",
      "Epoch 309/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3491 - accuracy: 0.8713 - val_loss: 0.3254 - val_accuracy: 0.8717\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.31246\n",
      "Epoch 310/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3178 - accuracy: 0.8842 - val_loss: 0.3279 - val_accuracy: 0.8672\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.31246\n",
      "Epoch 311/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3448 - accuracy: 0.8690 - val_loss: 0.3266 - val_accuracy: 0.8763\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.31246\n",
      "Epoch 312/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3569 - accuracy: 0.8641 - val_loss: 0.3223 - val_accuracy: 0.8695\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.31246\n",
      "Epoch 313/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3290 - accuracy: 0.8800 - val_loss: 0.3327 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.31246\n",
      "Epoch 314/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3332 - accuracy: 0.8762 - val_loss: 0.3173 - val_accuracy: 0.8717\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.31246\n",
      "Epoch 315/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3306 - accuracy: 0.8747 - val_loss: 0.3358 - val_accuracy: 0.8967\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.31246\n",
      "Epoch 316/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3462 - accuracy: 0.8702 - val_loss: 0.3243 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.31246\n",
      "Epoch 317/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3463 - accuracy: 0.8687 - val_loss: 0.3572 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.31246\n",
      "Epoch 318/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3590 - accuracy: 0.8660 - val_loss: 0.3188 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.31246\n",
      "Epoch 319/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3429 - accuracy: 0.8736 - val_loss: 0.3219 - val_accuracy: 0.8672\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.31246\n",
      "Epoch 320/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3365 - accuracy: 0.8702 - val_loss: 0.3248 - val_accuracy: 0.8797\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.31246\n",
      "Epoch 321/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3489 - accuracy: 0.8709 - val_loss: 0.3628 - val_accuracy: 0.8490\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.31246\n",
      "Epoch 322/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3414 - accuracy: 0.8724 - val_loss: 0.3262 - val_accuracy: 0.8831\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.31246\n",
      "Epoch 323/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3280 - accuracy: 0.8827 - val_loss: 0.3268 - val_accuracy: 0.8808\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.31246\n",
      "Epoch 324/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3329 - accuracy: 0.8740 - val_loss: 0.3125 - val_accuracy: 0.8797\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.31246\n",
      "Epoch 325/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.3390 - accuracy: 0.8687 - val_loss: 0.3943 - val_accuracy: 0.8502\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.31246\n",
      "Epoch 326/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3404 - accuracy: 0.8740 - val_loss: 0.3293 - val_accuracy: 0.8695\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.31246\n",
      "Epoch 327/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3258 - accuracy: 0.8706 - val_loss: 0.3272 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.31246\n",
      "Epoch 328/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3258 - accuracy: 0.8789 - val_loss: 0.3243 - val_accuracy: 0.8717\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.31246\n",
      "Epoch 329/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3244 - accuracy: 0.8762 - val_loss: 0.3276 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.31246\n",
      "Epoch 330/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3201 - accuracy: 0.8853 - val_loss: 0.3407 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.31246\n",
      "Epoch 331/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3249 - accuracy: 0.8902 - val_loss: 0.3310 - val_accuracy: 0.8627\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.31246\n",
      "Epoch 332/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.3211 - accuracy: 0.8823 - val_loss: 0.3192 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.31246\n",
      "Epoch 333/1000\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.3318 - accuracy: 0.8770 - val_loss: 0.3043 - val_accuracy: 0.8831\n",
      "\n",
      "Epoch 00333: val_loss improved from 0.31246 to 0.30431, saving model to models/classifier.hdf5\n",
      "Epoch 334/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3266 - accuracy: 0.8823 - val_loss: 0.3467 - val_accuracy: 0.8695\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.30431\n",
      "Epoch 335/1000\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.3158 - accuracy: 0.8827 - val_loss: 0.3210 - val_accuracy: 0.8774\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.30431\n",
      "Epoch 336/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.3458 - accuracy: 0.8690 - val_loss: 0.3169 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.30431\n",
      "Epoch 337/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3406 - accuracy: 0.8740 - val_loss: 0.3185 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.30431\n",
      "Epoch 338/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.3289 - accuracy: 0.8766 - val_loss: 0.3204 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.30431\n",
      "Epoch 339/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3287 - accuracy: 0.8736 - val_loss: 0.3524 - val_accuracy: 0.8581\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.30431\n",
      "Epoch 340/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.3320 - accuracy: 0.8759 - val_loss: 0.3362 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.30431\n",
      "Epoch 341/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.3306 - accuracy: 0.8766 - val_loss: 0.3350 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.30431\n",
      "Epoch 342/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.3304 - accuracy: 0.8781 - val_loss: 0.3012 - val_accuracy: 0.8808\n",
      "\n",
      "Epoch 00342: val_loss improved from 0.30431 to 0.30124, saving model to models/classifier.hdf5\n",
      "Epoch 343/1000\n",
      "42/42 [==============================] - 1s 27ms/step - loss: 0.3343 - accuracy: 0.8796 - val_loss: 0.3358 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.30124\n",
      "Epoch 344/1000\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3136 - accuracy: 0.8846 - val_loss: 0.3312 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.30124\n",
      "Epoch 345/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.3158 - accuracy: 0.8815 - val_loss: 0.3129 - val_accuracy: 0.8774\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.30124\n",
      "Epoch 346/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.3244 - accuracy: 0.8777 - val_loss: 0.3168 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.30124\n",
      "Epoch 347/1000\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.3091 - accuracy: 0.8853 - val_loss: 0.3215 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.30124\n",
      "Epoch 348/1000\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.3240 - accuracy: 0.8804 - val_loss: 0.3408 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.30124\n",
      "Epoch 349/1000\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.3121 - accuracy: 0.8838 - val_loss: 0.3262 - val_accuracy: 0.8717\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.30124\n",
      "Epoch 350/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3274 - accuracy: 0.8793 - val_loss: 0.3060 - val_accuracy: 0.8956\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.30124\n",
      "Epoch 351/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.3141 - accuracy: 0.8804 - val_loss: 0.3465 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.30124\n",
      "Epoch 352/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3217 - accuracy: 0.8876 - val_loss: 0.2969 - val_accuracy: 0.8933\n",
      "\n",
      "Epoch 00352: val_loss improved from 0.30124 to 0.29691, saving model to models/classifier.hdf5\n",
      "Epoch 353/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3205 - accuracy: 0.8842 - val_loss: 0.3048 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.29691\n",
      "Epoch 354/1000\n",
      "42/42 [==============================] - 1s 25ms/step - loss: 0.3178 - accuracy: 0.8785 - val_loss: 0.3254 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.29691\n",
      "Epoch 355/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.3456 - accuracy: 0.8721 - val_loss: 0.3175 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.29691\n",
      "Epoch 356/1000\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.3207 - accuracy: 0.8766 - val_loss: 0.3103 - val_accuracy: 0.8922\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.29691\n",
      "Epoch 357/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.3167 - accuracy: 0.8781 - val_loss: 0.3266 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.29691\n",
      "Epoch 358/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.3377 - accuracy: 0.8762 - val_loss: 0.3354 - val_accuracy: 0.8831\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.29691\n",
      "Epoch 359/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.3211 - accuracy: 0.8819 - val_loss: 0.3231 - val_accuracy: 0.8672\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.29691\n",
      "Epoch 360/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3170 - accuracy: 0.8819 - val_loss: 0.3186 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.29691\n",
      "Epoch 361/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.3193 - accuracy: 0.8827 - val_loss: 0.3157 - val_accuracy: 0.8717\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.29691\n",
      "Epoch 362/1000\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.3208 - accuracy: 0.8883 - val_loss: 0.3021 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.29691\n",
      "Epoch 363/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.3177 - accuracy: 0.8830 - val_loss: 0.3264 - val_accuracy: 0.8695\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.29691\n",
      "Epoch 364/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3156 - accuracy: 0.8815 - val_loss: 0.3403 - val_accuracy: 0.8672\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.29691\n",
      "Epoch 365/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3196 - accuracy: 0.8834 - val_loss: 0.3227 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.29691\n",
      "Epoch 366/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3144 - accuracy: 0.8857 - val_loss: 0.3121 - val_accuracy: 0.8763\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.29691\n",
      "Epoch 367/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3476 - accuracy: 0.8721 - val_loss: 0.3154 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.29691\n",
      "Epoch 368/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3261 - accuracy: 0.8857 - val_loss: 0.3342 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.29691\n",
      "Epoch 369/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.3268 - accuracy: 0.8800 - val_loss: 0.3121 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.29691\n",
      "Epoch 370/1000\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3225 - accuracy: 0.8823 - val_loss: 0.3054 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.29691\n",
      "Epoch 371/1000\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3220 - accuracy: 0.8830 - val_loss: 0.3166 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.29691\n",
      "Epoch 372/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.3216 - accuracy: 0.8762 - val_loss: 0.3331 - val_accuracy: 0.8627\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.29691\n",
      "Epoch 373/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3181 - accuracy: 0.8891 - val_loss: 0.3122 - val_accuracy: 0.8740\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.29691\n",
      "Epoch 374/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.3446 - accuracy: 0.8724 - val_loss: 0.3114 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.29691\n",
      "Epoch 375/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3022 - accuracy: 0.8899 - val_loss: 0.3617 - val_accuracy: 0.8570\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.29691\n",
      "Epoch 376/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.3341 - accuracy: 0.8770 - val_loss: 0.3084 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.29691\n",
      "Epoch 377/1000\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.3156 - accuracy: 0.8868 - val_loss: 0.3617 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.29691\n",
      "Epoch 378/1000\n",
      "42/42 [==============================] - 1s 26ms/step - loss: 0.3093 - accuracy: 0.8857 - val_loss: 0.3047 - val_accuracy: 0.8990\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.29691\n",
      "Epoch 379/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3053 - accuracy: 0.8872 - val_loss: 0.3221 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.29691\n",
      "Epoch 380/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3199 - accuracy: 0.8781 - val_loss: 0.2848 - val_accuracy: 0.8990\n",
      "\n",
      "Epoch 00380: val_loss improved from 0.29691 to 0.28476, saving model to models/classifier.hdf5\n",
      "Epoch 381/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3098 - accuracy: 0.8827 - val_loss: 0.3031 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.28476\n",
      "Epoch 382/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3198 - accuracy: 0.8902 - val_loss: 0.2997 - val_accuracy: 0.8910\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.28476\n",
      "Epoch 383/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2994 - accuracy: 0.8899 - val_loss: 0.2890 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.28476\n",
      "Epoch 384/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3132 - accuracy: 0.8755 - val_loss: 0.3622 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.28476\n",
      "Epoch 385/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3310 - accuracy: 0.8777 - val_loss: 0.3199 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.28476\n",
      "Epoch 386/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3091 - accuracy: 0.8891 - val_loss: 0.2892 - val_accuracy: 0.9047\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.28476\n",
      "Epoch 387/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3170 - accuracy: 0.8804 - val_loss: 0.3319 - val_accuracy: 0.8842\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.28476\n",
      "Epoch 388/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.3344 - accuracy: 0.8774 - val_loss: 0.3417 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.28476\n",
      "Epoch 389/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3037 - accuracy: 0.8883 - val_loss: 0.3070 - val_accuracy: 0.8751\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.28476\n",
      "Epoch 390/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3187 - accuracy: 0.8917 - val_loss: 0.3354 - val_accuracy: 0.8627\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.28476\n",
      "Epoch 391/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3356 - accuracy: 0.8736 - val_loss: 0.3500 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.28476\n",
      "Epoch 392/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3095 - accuracy: 0.8815 - val_loss: 0.3383 - val_accuracy: 0.8593\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.28476\n",
      "Epoch 393/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.3246 - accuracy: 0.8861 - val_loss: 0.3401 - val_accuracy: 0.8570\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.28476\n",
      "Epoch 394/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2998 - accuracy: 0.8929 - val_loss: 0.2985 - val_accuracy: 0.8751\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.28476\n",
      "Epoch 395/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3126 - accuracy: 0.8902 - val_loss: 0.2953 - val_accuracy: 0.8808\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.28476\n",
      "Epoch 396/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2991 - accuracy: 0.8902 - val_loss: 0.3008 - val_accuracy: 0.8797\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.28476\n",
      "Epoch 397/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3049 - accuracy: 0.8834 - val_loss: 0.2931 - val_accuracy: 0.8854\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.28476\n",
      "Epoch 398/1000\n",
      "42/42 [==============================] - 1s 23ms/step - loss: 0.3022 - accuracy: 0.8959 - val_loss: 0.3135 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.28476\n",
      "Epoch 399/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.3436 - accuracy: 0.8679 - val_loss: 0.3167 - val_accuracy: 0.8740\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.28476\n",
      "Epoch 400/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3107 - accuracy: 0.8925 - val_loss: 0.3244 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.28476\n",
      "Epoch 401/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3058 - accuracy: 0.8861 - val_loss: 0.3174 - val_accuracy: 0.8797\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.28476\n",
      "Epoch 402/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3044 - accuracy: 0.8868 - val_loss: 0.3046 - val_accuracy: 0.8990\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.28476\n",
      "Epoch 403/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.3129 - accuracy: 0.8793 - val_loss: 0.3633 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.28476\n",
      "Epoch 404/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.3190 - accuracy: 0.8819 - val_loss: 0.3328 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.28476\n",
      "Epoch 405/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3064 - accuracy: 0.8857 - val_loss: 0.3035 - val_accuracy: 0.8842\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.28476\n",
      "Epoch 406/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3011 - accuracy: 0.8895 - val_loss: 0.2897 - val_accuracy: 0.8933\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.28476\n",
      "Epoch 407/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2977 - accuracy: 0.8887 - val_loss: 0.3178 - val_accuracy: 0.8751\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.28476\n",
      "Epoch 408/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2958 - accuracy: 0.8929 - val_loss: 0.3088 - val_accuracy: 0.8717\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.28476\n",
      "Epoch 409/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3039 - accuracy: 0.8914 - val_loss: 0.3171 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.28476\n",
      "Epoch 410/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3109 - accuracy: 0.8880 - val_loss: 0.3097 - val_accuracy: 0.8774\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.28476\n",
      "Epoch 411/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3171 - accuracy: 0.8891 - val_loss: 0.2978 - val_accuracy: 0.8910\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.28476\n",
      "Epoch 412/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3069 - accuracy: 0.8925 - val_loss: 0.3056 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.28476\n",
      "Epoch 413/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.3078 - accuracy: 0.8827 - val_loss: 0.2956 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.28476\n",
      "Epoch 414/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3404 - accuracy: 0.8709 - val_loss: 0.2844 - val_accuracy: 0.8978\n",
      "\n",
      "Epoch 00414: val_loss improved from 0.28476 to 0.28436, saving model to models/classifier.hdf5\n",
      "Epoch 415/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3152 - accuracy: 0.8853 - val_loss: 0.3045 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.28436\n",
      "Epoch 416/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2900 - accuracy: 0.8967 - val_loss: 0.2988 - val_accuracy: 0.8831\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.28436\n",
      "Epoch 417/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3013 - accuracy: 0.8921 - val_loss: 0.3131 - val_accuracy: 0.8797\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.28436\n",
      "Epoch 418/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3030 - accuracy: 0.8921 - val_loss: 0.2924 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.28436\n",
      "Epoch 419/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2969 - accuracy: 0.8993 - val_loss: 0.3055 - val_accuracy: 0.8842\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.28436\n",
      "Epoch 420/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2949 - accuracy: 0.8925 - val_loss: 0.2930 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.28436\n",
      "Epoch 421/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3199 - accuracy: 0.8864 - val_loss: 0.2896 - val_accuracy: 0.8944\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.28436\n",
      "Epoch 422/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3195 - accuracy: 0.8834 - val_loss: 0.3401 - val_accuracy: 0.8717\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.28436\n",
      "Epoch 423/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3047 - accuracy: 0.8846 - val_loss: 0.3007 - val_accuracy: 0.8763\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.28436\n",
      "Epoch 424/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3274 - accuracy: 0.8777 - val_loss: 0.2983 - val_accuracy: 0.8922\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.28436\n",
      "Epoch 425/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.2984 - accuracy: 0.8925 - val_loss: 0.3042 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.28436\n",
      "Epoch 426/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2940 - accuracy: 0.8959 - val_loss: 0.2979 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.28436\n",
      "Epoch 427/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3007 - accuracy: 0.8948 - val_loss: 0.2859 - val_accuracy: 0.8990\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.28436\n",
      "Epoch 428/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2900 - accuracy: 0.8982 - val_loss: 0.2868 - val_accuracy: 0.9047\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.28436\n",
      "Epoch 429/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2979 - accuracy: 0.8933 - val_loss: 0.3117 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.28436\n",
      "Epoch 430/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2995 - accuracy: 0.8906 - val_loss: 0.2883 - val_accuracy: 0.8944\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.28436\n",
      "Epoch 431/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2958 - accuracy: 0.8978 - val_loss: 0.2933 - val_accuracy: 0.9160\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.28436\n",
      "Epoch 432/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.2980 - accuracy: 0.8940 - val_loss: 0.2978 - val_accuracy: 0.8808\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.28436\n",
      "Epoch 433/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2937 - accuracy: 0.8906 - val_loss: 0.2880 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.28436\n",
      "Epoch 434/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3160 - accuracy: 0.8815 - val_loss: 0.2902 - val_accuracy: 0.8797\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.28436\n",
      "Epoch 435/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2928 - accuracy: 0.8967 - val_loss: 0.2864 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.28436\n",
      "Epoch 436/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3134 - accuracy: 0.8785 - val_loss: 0.2787 - val_accuracy: 0.8944\n",
      "\n",
      "Epoch 00436: val_loss improved from 0.28436 to 0.27872, saving model to models/classifier.hdf5\n",
      "Epoch 437/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3217 - accuracy: 0.8796 - val_loss: 0.2972 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.27872\n",
      "Epoch 438/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3125 - accuracy: 0.8796 - val_loss: 0.3061 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.27872\n",
      "Epoch 439/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2908 - accuracy: 0.8959 - val_loss: 0.3074 - val_accuracy: 0.8774\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.27872\n",
      "Epoch 440/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3055 - accuracy: 0.8876 - val_loss: 0.3237 - val_accuracy: 0.8717\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.27872\n",
      "Epoch 441/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3147 - accuracy: 0.8853 - val_loss: 0.3632 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.27872\n",
      "Epoch 442/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3058 - accuracy: 0.8887 - val_loss: 0.3140 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.27872\n",
      "Epoch 443/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2878 - accuracy: 0.8982 - val_loss: 0.2885 - val_accuracy: 0.8922\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.27872\n",
      "Epoch 444/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3017 - accuracy: 0.8891 - val_loss: 0.2822 - val_accuracy: 0.8944\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.27872\n",
      "Epoch 445/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2832 - accuracy: 0.8982 - val_loss: 0.3123 - val_accuracy: 0.8740\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.27872\n",
      "Epoch 446/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2999 - accuracy: 0.8967 - val_loss: 0.3154 - val_accuracy: 0.8751\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.27872\n",
      "Epoch 447/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3048 - accuracy: 0.8857 - val_loss: 0.2997 - val_accuracy: 0.8763\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.27872\n",
      "Epoch 448/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2941 - accuracy: 0.8978 - val_loss: 0.2955 - val_accuracy: 0.8842\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.27872\n",
      "Epoch 449/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2879 - accuracy: 0.8989 - val_loss: 0.3089 - val_accuracy: 0.8774\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.27872\n",
      "Epoch 450/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2883 - accuracy: 0.9008 - val_loss: 0.3165 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.27872\n",
      "Epoch 451/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2915 - accuracy: 0.8936 - val_loss: 0.2929 - val_accuracy: 0.8933\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.27872\n",
      "Epoch 452/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2933 - accuracy: 0.8948 - val_loss: 0.2953 - val_accuracy: 0.8831\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.27872\n",
      "Epoch 453/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.3087 - accuracy: 0.8899 - val_loss: 0.2883 - val_accuracy: 0.8922\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.27872\n",
      "Epoch 454/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3015 - accuracy: 0.8929 - val_loss: 0.2894 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.27872\n",
      "Epoch 455/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3065 - accuracy: 0.8910 - val_loss: 0.3175 - val_accuracy: 0.8740\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.27872\n",
      "Epoch 456/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.3004 - accuracy: 0.8853 - val_loss: 0.3039 - val_accuracy: 0.8774\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.27872\n",
      "Epoch 457/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2968 - accuracy: 0.8940 - val_loss: 0.2901 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.27872\n",
      "Epoch 458/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2893 - accuracy: 0.8982 - val_loss: 0.3492 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.27872\n",
      "Epoch 459/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2864 - accuracy: 0.8970 - val_loss: 0.3041 - val_accuracy: 0.8854\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.27872\n",
      "Epoch 460/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3013 - accuracy: 0.8891 - val_loss: 0.3572 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.27872\n",
      "Epoch 461/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2805 - accuracy: 0.8952 - val_loss: 0.2990 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.27872\n",
      "Epoch 462/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2830 - accuracy: 0.9012 - val_loss: 0.2779 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00462: val_loss improved from 0.27872 to 0.27793, saving model to models/classifier.hdf5\n",
      "Epoch 463/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2850 - accuracy: 0.9012 - val_loss: 0.3287 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.27793\n",
      "Epoch 464/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2870 - accuracy: 0.8967 - val_loss: 0.2749 - val_accuracy: 0.9058\n",
      "\n",
      "Epoch 00464: val_loss improved from 0.27793 to 0.27487, saving model to models/classifier.hdf5\n",
      "Epoch 465/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3125 - accuracy: 0.8887 - val_loss: 0.2998 - val_accuracy: 0.8933\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.27487\n",
      "Epoch 466/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2896 - accuracy: 0.9012 - val_loss: 0.3023 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.27487\n",
      "Epoch 467/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2906 - accuracy: 0.8910 - val_loss: 0.2927 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.27487\n",
      "Epoch 468/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.3114 - accuracy: 0.8815 - val_loss: 0.2772 - val_accuracy: 0.9058\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.27487\n",
      "Epoch 469/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2783 - accuracy: 0.9050 - val_loss: 0.2849 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.27487\n",
      "Epoch 470/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2764 - accuracy: 0.9042 - val_loss: 0.3235 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.27487\n",
      "Epoch 471/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2981 - accuracy: 0.8876 - val_loss: 0.2753 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.27487\n",
      "Epoch 472/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2849 - accuracy: 0.8970 - val_loss: 0.3222 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.27487\n",
      "Epoch 473/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2833 - accuracy: 0.8967 - val_loss: 0.3432 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.27487\n",
      "Epoch 474/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.3020 - accuracy: 0.8910 - val_loss: 0.2953 - val_accuracy: 0.8956\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.27487\n",
      "Epoch 475/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2889 - accuracy: 0.8955 - val_loss: 0.3124 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.27487\n",
      "Epoch 476/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2976 - accuracy: 0.9001 - val_loss: 0.2692 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00476: val_loss improved from 0.27487 to 0.26917, saving model to models/classifier.hdf5\n",
      "Epoch 477/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2872 - accuracy: 0.9046 - val_loss: 0.3001 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.26917\n",
      "Epoch 478/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2943 - accuracy: 0.8906 - val_loss: 0.2709 - val_accuracy: 0.8944\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.26917\n",
      "Epoch 479/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2859 - accuracy: 0.8963 - val_loss: 0.2694 - val_accuracy: 0.9012\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.26917\n",
      "Epoch 480/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2770 - accuracy: 0.8982 - val_loss: 0.2925 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.26917\n",
      "Epoch 481/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2832 - accuracy: 0.9008 - val_loss: 0.2760 - val_accuracy: 0.8922\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.26917\n",
      "Epoch 482/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2972 - accuracy: 0.8914 - val_loss: 0.3147 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.26917\n",
      "Epoch 483/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2967 - accuracy: 0.8974 - val_loss: 0.2889 - val_accuracy: 0.8842\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.26917\n",
      "Epoch 484/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2798 - accuracy: 0.8970 - val_loss: 0.2956 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.26917\n",
      "Epoch 485/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2797 - accuracy: 0.8970 - val_loss: 0.2867 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.26917\n",
      "Epoch 486/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2922 - accuracy: 0.8997 - val_loss: 0.2868 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.26917\n",
      "Epoch 487/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2757 - accuracy: 0.8974 - val_loss: 0.2880 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.26917\n",
      "Epoch 488/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.3053 - accuracy: 0.8857 - val_loss: 0.3031 - val_accuracy: 0.8831\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.26917\n",
      "Epoch 489/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2894 - accuracy: 0.8978 - val_loss: 0.2857 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.26917\n",
      "Epoch 490/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2851 - accuracy: 0.8944 - val_loss: 0.2817 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.26917\n",
      "Epoch 491/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2771 - accuracy: 0.8993 - val_loss: 0.3120 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.26917\n",
      "Epoch 492/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2759 - accuracy: 0.9020 - val_loss: 0.2663 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00492: val_loss improved from 0.26917 to 0.26630, saving model to models/classifier.hdf5\n",
      "Epoch 493/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2689 - accuracy: 0.9061 - val_loss: 0.2825 - val_accuracy: 0.8933\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.26630\n",
      "Epoch 494/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2723 - accuracy: 0.9061 - val_loss: 0.2903 - val_accuracy: 0.9012\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.26630\n",
      "Epoch 495/1000\n",
      "42/42 [==============================] - 1s 22ms/step - loss: 0.2730 - accuracy: 0.9046 - val_loss: 0.2624 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00495: val_loss improved from 0.26630 to 0.26242, saving model to models/classifier.hdf5\n",
      "Epoch 496/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2845 - accuracy: 0.8952 - val_loss: 0.2730 - val_accuracy: 0.9047\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.26242\n",
      "Epoch 497/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2884 - accuracy: 0.9039 - val_loss: 0.2791 - val_accuracy: 0.8978\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.26242\n",
      "Epoch 498/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2936 - accuracy: 0.9016 - val_loss: 0.2715 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.26242\n",
      "Epoch 499/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2900 - accuracy: 0.8929 - val_loss: 0.2860 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.26242\n",
      "Epoch 500/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2738 - accuracy: 0.9001 - val_loss: 0.3125 - val_accuracy: 0.8774\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.26242\n",
      "Epoch 501/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2856 - accuracy: 0.9005 - val_loss: 0.2983 - val_accuracy: 0.8831\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.26242\n",
      "Epoch 502/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2804 - accuracy: 0.9005 - val_loss: 0.3116 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.26242\n",
      "Epoch 503/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2963 - accuracy: 0.8978 - val_loss: 0.2896 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.26242\n",
      "Epoch 504/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.2759 - accuracy: 0.9042 - val_loss: 0.2917 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.26242\n",
      "Epoch 505/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2729 - accuracy: 0.9084 - val_loss: 0.2583 - val_accuracy: 0.9160\n",
      "\n",
      "Epoch 00505: val_loss improved from 0.26242 to 0.25831, saving model to models/classifier.hdf5\n",
      "Epoch 506/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2980 - accuracy: 0.8883 - val_loss: 0.2625 - val_accuracy: 0.9160\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.25831\n",
      "Epoch 507/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2772 - accuracy: 0.8997 - val_loss: 0.2909 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.25831\n",
      "Epoch 508/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2860 - accuracy: 0.9020 - val_loss: 0.2920 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.25831\n",
      "Epoch 509/1000\n",
      "42/42 [==============================] - 1s 28ms/step - loss: 0.2948 - accuracy: 0.8970 - val_loss: 0.2571 - val_accuracy: 0.9160\n",
      "\n",
      "Epoch 00509: val_loss improved from 0.25831 to 0.25708, saving model to models/classifier.hdf5\n",
      "Epoch 510/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2851 - accuracy: 0.8982 - val_loss: 0.2683 - val_accuracy: 0.9012\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.25708\n",
      "Epoch 511/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2791 - accuracy: 0.9020 - val_loss: 0.2752 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.25708\n",
      "Epoch 512/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2830 - accuracy: 0.8989 - val_loss: 0.3399 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.25708\n",
      "Epoch 513/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2864 - accuracy: 0.8974 - val_loss: 0.2746 - val_accuracy: 0.9012\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.25708\n",
      "Epoch 514/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2811 - accuracy: 0.8986 - val_loss: 0.2976 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.25708\n",
      "Epoch 515/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2956 - accuracy: 0.8963 - val_loss: 0.2963 - val_accuracy: 0.8854\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.25708\n",
      "Epoch 516/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.3146 - accuracy: 0.8838 - val_loss: 0.2826 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.25708\n",
      "Epoch 517/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2803 - accuracy: 0.9001 - val_loss: 0.2840 - val_accuracy: 0.8910\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.25708\n",
      "Epoch 518/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2788 - accuracy: 0.8970 - val_loss: 0.2738 - val_accuracy: 0.9047\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.25708\n",
      "Epoch 519/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2884 - accuracy: 0.9023 - val_loss: 0.2709 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.25708\n",
      "Epoch 520/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2734 - accuracy: 0.9008 - val_loss: 0.2640 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.25708\n",
      "Epoch 521/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2826 - accuracy: 0.9023 - val_loss: 0.2820 - val_accuracy: 0.8922\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.25708\n",
      "Epoch 522/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2944 - accuracy: 0.8895 - val_loss: 0.2824 - val_accuracy: 0.8922\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.25708\n",
      "Epoch 523/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.3003 - accuracy: 0.8936 - val_loss: 0.2922 - val_accuracy: 0.8967\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.25708\n",
      "Epoch 524/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2883 - accuracy: 0.9027 - val_loss: 0.2873 - val_accuracy: 0.8990\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.25708\n",
      "Epoch 525/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2914 - accuracy: 0.8982 - val_loss: 0.3005 - val_accuracy: 0.8808\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.25708\n",
      "Epoch 526/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2798 - accuracy: 0.8944 - val_loss: 0.2637 - val_accuracy: 0.9183\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.25708\n",
      "Epoch 527/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2757 - accuracy: 0.9065 - val_loss: 0.2664 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.25708\n",
      "Epoch 528/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2758 - accuracy: 0.9039 - val_loss: 0.2517 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00528: val_loss improved from 0.25708 to 0.25165, saving model to models/classifier.hdf5\n",
      "Epoch 529/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2753 - accuracy: 0.9065 - val_loss: 0.2571 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.25165\n",
      "Epoch 530/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2695 - accuracy: 0.9046 - val_loss: 0.2720 - val_accuracy: 0.9092\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.25165\n",
      "Epoch 531/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2871 - accuracy: 0.8944 - val_loss: 0.2684 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.25165\n",
      "Epoch 532/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2709 - accuracy: 0.9023 - val_loss: 0.3432 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.25165\n",
      "Epoch 533/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2622 - accuracy: 0.9118 - val_loss: 0.2798 - val_accuracy: 0.8944\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.25165\n",
      "Epoch 534/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2738 - accuracy: 0.9065 - val_loss: 0.3328 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.25165\n",
      "Epoch 535/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.2664 - accuracy: 0.9027 - val_loss: 0.2965 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.25165\n",
      "Epoch 536/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2674 - accuracy: 0.9084 - val_loss: 0.2804 - val_accuracy: 0.8910\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.25165\n",
      "Epoch 537/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2691 - accuracy: 0.9005 - val_loss: 0.2911 - val_accuracy: 0.8922\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.25165\n",
      "Epoch 538/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2648 - accuracy: 0.9118 - val_loss: 0.3310 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.25165\n",
      "Epoch 539/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2690 - accuracy: 0.9039 - val_loss: 0.2756 - val_accuracy: 0.9069\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.25165\n",
      "Epoch 540/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.2830 - accuracy: 0.9073 - val_loss: 0.2824 - val_accuracy: 0.8922\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.25165\n",
      "Epoch 541/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2779 - accuracy: 0.9031 - val_loss: 0.2676 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.25165\n",
      "Epoch 542/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.2708 - accuracy: 0.9073 - val_loss: 0.3219 - val_accuracy: 0.8797\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.25165\n",
      "Epoch 543/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.2786 - accuracy: 0.9005 - val_loss: 0.2671 - val_accuracy: 0.9069\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.25165\n",
      "Epoch 544/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2800 - accuracy: 0.9046 - val_loss: 0.2868 - val_accuracy: 0.8956\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.25165\n",
      "Epoch 545/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2793 - accuracy: 0.9012 - val_loss: 0.3157 - val_accuracy: 0.8797\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.25165\n",
      "Epoch 546/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2895 - accuracy: 0.9008 - val_loss: 0.2888 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.25165\n",
      "Epoch 547/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2807 - accuracy: 0.9001 - val_loss: 0.2812 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.25165\n",
      "Epoch 548/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2694 - accuracy: 0.9073 - val_loss: 0.2566 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.25165\n",
      "Epoch 549/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2717 - accuracy: 0.9031 - val_loss: 0.2639 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.25165\n",
      "Epoch 550/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2729 - accuracy: 0.9008 - val_loss: 0.2591 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.25165\n",
      "Epoch 551/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2742 - accuracy: 0.9054 - val_loss: 0.2659 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.25165\n",
      "Epoch 552/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2674 - accuracy: 0.9092 - val_loss: 0.3004 - val_accuracy: 0.8808\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.25165\n",
      "Epoch 553/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2716 - accuracy: 0.9084 - val_loss: 0.2884 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.25165\n",
      "Epoch 554/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2680 - accuracy: 0.9099 - val_loss: 0.2756 - val_accuracy: 0.8978\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.25165\n",
      "Epoch 555/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2640 - accuracy: 0.9122 - val_loss: 0.3004 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.25165\n",
      "Epoch 556/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2660 - accuracy: 0.9069 - val_loss: 0.2761 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.25165\n",
      "Epoch 557/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2797 - accuracy: 0.8993 - val_loss: 0.2892 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.25165\n",
      "Epoch 558/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.2674 - accuracy: 0.9054 - val_loss: 0.2894 - val_accuracy: 0.8910\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.25165\n",
      "Epoch 559/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2853 - accuracy: 0.9058 - val_loss: 0.2910 - val_accuracy: 0.8933\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.25165\n",
      "Epoch 560/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2735 - accuracy: 0.9039 - val_loss: 0.2757 - val_accuracy: 0.8990\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.25165\n",
      "Epoch 561/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2723 - accuracy: 0.9039 - val_loss: 0.3061 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.25165\n",
      "Epoch 562/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2604 - accuracy: 0.9141 - val_loss: 0.2450 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00562: val_loss improved from 0.25165 to 0.24500, saving model to models/classifier.hdf5\n",
      "Epoch 563/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2854 - accuracy: 0.8989 - val_loss: 0.2825 - val_accuracy: 0.9035\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.24500\n",
      "Epoch 564/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2870 - accuracy: 0.8997 - val_loss: 0.2801 - val_accuracy: 0.9012\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.24500\n",
      "Epoch 565/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2963 - accuracy: 0.8970 - val_loss: 0.2669 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.24500\n",
      "Epoch 566/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.2690 - accuracy: 0.9061 - val_loss: 0.2868 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.24500\n",
      "Epoch 567/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2790 - accuracy: 0.9035 - val_loss: 0.2634 - val_accuracy: 0.9069\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.24500\n",
      "Epoch 568/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2830 - accuracy: 0.8974 - val_loss: 0.2575 - val_accuracy: 0.9047\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.24500\n",
      "Epoch 569/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.2856 - accuracy: 0.8944 - val_loss: 0.2881 - val_accuracy: 0.8910\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.24500\n",
      "Epoch 570/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2885 - accuracy: 0.9008 - val_loss: 0.2709 - val_accuracy: 0.9183\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.24500\n",
      "Epoch 571/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2864 - accuracy: 0.9039 - val_loss: 0.2627 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.24500\n",
      "Epoch 572/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2769 - accuracy: 0.8986 - val_loss: 0.2480 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.24500\n",
      "Epoch 573/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2782 - accuracy: 0.9031 - val_loss: 0.2515 - val_accuracy: 0.9183\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.24500\n",
      "Epoch 574/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.2744 - accuracy: 0.9012 - val_loss: 0.2478 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.24500\n",
      "Epoch 575/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2675 - accuracy: 0.9054 - val_loss: 0.2704 - val_accuracy: 0.9024\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.24500\n",
      "Epoch 576/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2657 - accuracy: 0.9080 - val_loss: 0.2946 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.24500\n",
      "Epoch 577/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2661 - accuracy: 0.9073 - val_loss: 0.2825 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.24500\n",
      "Epoch 578/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2702 - accuracy: 0.9111 - val_loss: 0.3234 - val_accuracy: 0.8808\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.24500\n",
      "Epoch 579/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2702 - accuracy: 0.9061 - val_loss: 0.3080 - val_accuracy: 0.8808\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.24500\n",
      "Epoch 580/1000\n",
      "42/42 [==============================] - 1s 24ms/step - loss: 0.2848 - accuracy: 0.9016 - val_loss: 0.2943 - val_accuracy: 0.9012\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.24500\n",
      "Epoch 581/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2694 - accuracy: 0.9035 - val_loss: 0.2597 - val_accuracy: 0.9149\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.24500\n",
      "Epoch 582/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2591 - accuracy: 0.9076 - val_loss: 0.2800 - val_accuracy: 0.8956\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.24500\n",
      "Epoch 583/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2647 - accuracy: 0.9095 - val_loss: 0.3114 - val_accuracy: 0.8774\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.24500\n",
      "Epoch 584/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2746 - accuracy: 0.9020 - val_loss: 0.3168 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.24500\n",
      "Epoch 585/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2665 - accuracy: 0.9156 - val_loss: 0.3130 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.24500\n",
      "Epoch 586/1000\n",
      "42/42 [==============================] - 1s 21ms/step - loss: 0.2704 - accuracy: 0.9035 - val_loss: 0.2665 - val_accuracy: 0.9001\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.24500\n",
      "Epoch 587/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2554 - accuracy: 0.9118 - val_loss: 0.3029 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.24500\n",
      "Epoch 588/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2597 - accuracy: 0.9129 - val_loss: 0.2884 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.24500\n",
      "Epoch 589/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2735 - accuracy: 0.9054 - val_loss: 0.2976 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.24500\n",
      "Epoch 590/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2543 - accuracy: 0.9171 - val_loss: 0.2780 - val_accuracy: 0.8978\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.24500\n",
      "Epoch 591/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2595 - accuracy: 0.9012 - val_loss: 0.2504 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.24500\n",
      "Epoch 592/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2731 - accuracy: 0.9080 - val_loss: 0.2565 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.24500\n",
      "Epoch 593/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2766 - accuracy: 0.9069 - val_loss: 0.2729 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.24500\n",
      "Epoch 594/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2685 - accuracy: 0.9069 - val_loss: 0.2693 - val_accuracy: 0.9058\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.24500\n",
      "Epoch 595/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2714 - accuracy: 0.9008 - val_loss: 0.3094 - val_accuracy: 0.8854\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.24500\n",
      "Epoch 596/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2631 - accuracy: 0.9126 - val_loss: 0.2741 - val_accuracy: 0.8956\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.24500\n",
      "Epoch 597/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2735 - accuracy: 0.9050 - val_loss: 0.2591 - val_accuracy: 0.9092\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.24500\n",
      "Epoch 598/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2706 - accuracy: 0.9080 - val_loss: 0.2842 - val_accuracy: 0.8967\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.24500\n",
      "Epoch 599/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2558 - accuracy: 0.9137 - val_loss: 0.2613 - val_accuracy: 0.9092\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.24500\n",
      "Epoch 600/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2828 - accuracy: 0.8978 - val_loss: 0.2968 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.24500\n",
      "Epoch 601/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.2592 - accuracy: 0.9118 - val_loss: 0.2763 - val_accuracy: 0.9047\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.24500\n",
      "Epoch 602/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2560 - accuracy: 0.9148 - val_loss: 0.2541 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.24500\n",
      "Epoch 603/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2685 - accuracy: 0.9103 - val_loss: 0.2731 - val_accuracy: 0.9024\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.24500\n",
      "Epoch 604/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2641 - accuracy: 0.9114 - val_loss: 0.2413 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00604: val_loss improved from 0.24500 to 0.24129, saving model to models/classifier.hdf5\n",
      "Epoch 605/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2717 - accuracy: 0.9016 - val_loss: 0.2816 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.24129\n",
      "Epoch 606/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2565 - accuracy: 0.9126 - val_loss: 0.3020 - val_accuracy: 0.8820\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.24129\n",
      "Epoch 607/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2785 - accuracy: 0.9046 - val_loss: 0.2508 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.24129\n",
      "Epoch 608/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2779 - accuracy: 0.9084 - val_loss: 0.3149 - val_accuracy: 0.8797\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.24129\n",
      "Epoch 609/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2615 - accuracy: 0.9050 - val_loss: 0.2631 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.24129\n",
      "Epoch 610/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2549 - accuracy: 0.9137 - val_loss: 0.2991 - val_accuracy: 0.8831\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.24129\n",
      "Epoch 611/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2725 - accuracy: 0.9027 - val_loss: 0.2895 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.24129\n",
      "Epoch 612/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2776 - accuracy: 0.9069 - val_loss: 0.2609 - val_accuracy: 0.9069\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.24129\n",
      "Epoch 613/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2850 - accuracy: 0.9065 - val_loss: 0.2611 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.24129\n",
      "Epoch 614/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2684 - accuracy: 0.9092 - val_loss: 0.2588 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.24129\n",
      "Epoch 615/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2597 - accuracy: 0.9179 - val_loss: 0.2616 - val_accuracy: 0.9092\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.24129\n",
      "Epoch 616/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2574 - accuracy: 0.9065 - val_loss: 0.2361 - val_accuracy: 0.9183\n",
      "\n",
      "Epoch 00616: val_loss improved from 0.24129 to 0.23606, saving model to models/classifier.hdf5\n",
      "Epoch 617/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2765 - accuracy: 0.8978 - val_loss: 0.2991 - val_accuracy: 0.8933\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.23606\n",
      "Epoch 618/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2591 - accuracy: 0.9145 - val_loss: 0.2912 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.23606\n",
      "Epoch 619/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2643 - accuracy: 0.9114 - val_loss: 0.2719 - val_accuracy: 0.8990\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.23606\n",
      "Epoch 620/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2890 - accuracy: 0.8974 - val_loss: 0.3236 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.23606\n",
      "Epoch 621/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2870 - accuracy: 0.8959 - val_loss: 0.2841 - val_accuracy: 0.8910\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.23606\n",
      "Epoch 622/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2662 - accuracy: 0.9031 - val_loss: 0.2601 - val_accuracy: 0.9092\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.23606\n",
      "Epoch 623/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2552 - accuracy: 0.9118 - val_loss: 0.2899 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.23606\n",
      "Epoch 624/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2662 - accuracy: 0.9050 - val_loss: 0.2580 - val_accuracy: 0.9069\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.23606\n",
      "Epoch 625/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2633 - accuracy: 0.9148 - val_loss: 0.2623 - val_accuracy: 0.9069\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.23606\n",
      "Epoch 626/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2587 - accuracy: 0.9095 - val_loss: 0.2655 - val_accuracy: 0.9024\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.23606\n",
      "Epoch 627/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2628 - accuracy: 0.9076 - val_loss: 0.3274 - val_accuracy: 0.8808\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.23606\n",
      "Epoch 628/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2561 - accuracy: 0.9099 - val_loss: 0.2685 - val_accuracy: 0.9092\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.23606\n",
      "Epoch 629/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2751 - accuracy: 0.9031 - val_loss: 0.2768 - val_accuracy: 0.9012\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.23606\n",
      "Epoch 630/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2653 - accuracy: 0.9137 - val_loss: 0.2554 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.23606\n",
      "Epoch 631/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2543 - accuracy: 0.9145 - val_loss: 0.2672 - val_accuracy: 0.9058\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.23606\n",
      "Epoch 632/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2559 - accuracy: 0.9145 - val_loss: 0.2585 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.23606\n",
      "Epoch 633/1000\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.2781 - accuracy: 0.9050 - val_loss: 0.2572 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.23606\n",
      "Epoch 634/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2631 - accuracy: 0.9080 - val_loss: 0.2797 - val_accuracy: 0.9069\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.23606\n",
      "Epoch 635/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2558 - accuracy: 0.9148 - val_loss: 0.2908 - val_accuracy: 0.8842\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.23606\n",
      "Epoch 636/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2605 - accuracy: 0.9095 - val_loss: 0.2577 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.23606\n",
      "Epoch 637/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2660 - accuracy: 0.9061 - val_loss: 0.2707 - val_accuracy: 0.9001\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.23606\n",
      "Epoch 638/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2542 - accuracy: 0.9133 - val_loss: 0.2991 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.23606\n",
      "Epoch 639/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2641 - accuracy: 0.9099 - val_loss: 0.2416 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.23606\n",
      "Epoch 640/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2632 - accuracy: 0.9005 - val_loss: 0.2621 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.23606\n",
      "Epoch 641/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2471 - accuracy: 0.9186 - val_loss: 0.2490 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.23606\n",
      "Epoch 642/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2501 - accuracy: 0.9126 - val_loss: 0.2662 - val_accuracy: 0.9024\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.23606\n",
      "Epoch 643/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2727 - accuracy: 0.9016 - val_loss: 0.2403 - val_accuracy: 0.9296\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.23606\n",
      "Epoch 644/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2709 - accuracy: 0.9035 - val_loss: 0.2562 - val_accuracy: 0.9262\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.23606\n",
      "Epoch 645/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2689 - accuracy: 0.9023 - val_loss: 0.2413 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.23606\n",
      "Epoch 646/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2610 - accuracy: 0.9069 - val_loss: 0.2534 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.23606\n",
      "Epoch 647/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2490 - accuracy: 0.9111 - val_loss: 0.2396 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.23606\n",
      "Epoch 648/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2606 - accuracy: 0.9133 - val_loss: 0.2757 - val_accuracy: 0.8967\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.23606\n",
      "Epoch 649/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2506 - accuracy: 0.9194 - val_loss: 0.3183 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.23606\n",
      "Epoch 650/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2738 - accuracy: 0.9069 - val_loss: 0.2902 - val_accuracy: 0.8967\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.23606\n",
      "Epoch 651/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2538 - accuracy: 0.9152 - val_loss: 0.3134 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.23606\n",
      "Epoch 652/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2581 - accuracy: 0.9073 - val_loss: 0.3053 - val_accuracy: 0.8854\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.23606\n",
      "Epoch 653/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2524 - accuracy: 0.9126 - val_loss: 0.2608 - val_accuracy: 0.9047\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.23606\n",
      "Epoch 654/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2623 - accuracy: 0.9061 - val_loss: 0.2697 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.23606\n",
      "Epoch 655/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2655 - accuracy: 0.9035 - val_loss: 0.2927 - val_accuracy: 0.9058\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.23606\n",
      "Epoch 656/1000\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.2583 - accuracy: 0.9126 - val_loss: 0.2539 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.23606\n",
      "Epoch 657/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2578 - accuracy: 0.9114 - val_loss: 0.2672 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.23606\n",
      "Epoch 658/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2506 - accuracy: 0.9164 - val_loss: 0.2533 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.23606\n",
      "Epoch 659/1000\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.2418 - accuracy: 0.9156 - val_loss: 0.2367 - val_accuracy: 0.9330\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.23606\n",
      "Epoch 660/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2617 - accuracy: 0.9099 - val_loss: 0.2851 - val_accuracy: 0.8944\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.23606\n",
      "Epoch 661/1000\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.2591 - accuracy: 0.9092 - val_loss: 0.2941 - val_accuracy: 0.8910\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.23606\n",
      "Epoch 662/1000\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 0.2424 - accuracy: 0.9099 - val_loss: 0.2670 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.23606\n",
      "Epoch 663/1000\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 0.2561 - accuracy: 0.9111 - val_loss: 0.2796 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.23606\n",
      "Epoch 664/1000\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.2438 - accuracy: 0.9114 - val_loss: 0.2472 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.23606\n",
      "Epoch 665/1000\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.2588 - accuracy: 0.9076 - val_loss: 0.2702 - val_accuracy: 0.9183\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.23606\n",
      "Epoch 666/1000\n",
      "42/42 [==============================] - 1s 20ms/step - loss: 0.2693 - accuracy: 0.9023 - val_loss: 0.2510 - val_accuracy: 0.9183\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.23606\n",
      "Epoch 00666: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28cae1e20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2361 - accuracy: 0.9183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 19:36:50.262365: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_save_path)\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 19:36:56.087189: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2063740e-04 5.2789921e-01 5.2896069e-14 1.7285601e-20 1.2003147e-10\n",
      " 4.7176611e-01 5.0331753e-11 7.4186154e-13 1.4824805e-20 2.1403500e-04]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.95      0.89        66\n",
      "         1.0       0.79      0.92      0.85        90\n",
      "         2.0       0.94      0.84      0.89        75\n",
      "         3.0       0.97      1.00      0.98        87\n",
      "         4.0       0.97      1.00      0.98        84\n",
      "         5.0       0.92      0.79      0.85        99\n",
      "         6.0       0.91      1.00      0.95        95\n",
      "         7.0       0.91      0.99      0.95        85\n",
      "         8.0       0.99      1.00      1.00       103\n",
      "         9.0       0.97      0.71      0.82        97\n",
      "\n",
      "    accuracy                           0.92       881\n",
      "   macro avg       0.92      0.92      0.92       881\n",
      "weighted avg       0.92      0.92      0.92       881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, dict_keys=None, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    if dict_keys:\n",
    "        labels = [dict_keys[x] for x in labels]\n",
    "\n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred, {v: k for k, v in classes.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 20:27:36.628938: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/3w/bsb667zn42gdhbqq3z8ptmgw0000gn/T/tmpt4s7ox_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-23 20:27:37.072456: I tensorflow/core/grappler/devices.cc:78] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-07-23 20:27:37.076387: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-07-23 20:27:37.080227: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-23 20:27:37.080364: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-07-23 20:27:37.130244: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n",
      "2022-07-23 20:27:37.326483: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:345] Ignored output_format.\n",
      "2022-07-23 20:27:37.326502: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:348] Ignored drop_control_dependency.\n",
      "2022-07-23 20:27:37.341709: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-07-23 20:27:37.355225: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-23 20:27:37.355254: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-07-23 20:27:37.383392: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor sequential/dense_2/MatMul because it has fewer than 1024 elements (512).\n",
      "2022-07-23 20:27:37.383407: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor sequential/dense_3/MatMul because it has fewer than 1024 elements (160).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7840"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save as a model dedicated to inference\n",
    "model.save(model_save_path, include_optimizer=False)\n",
    "\n",
    "# Transform model (quantization)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get I / O tensor\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 658 s, sys: 1.1 ms, total: 1.76 ms\n",
      "Wall time: 988 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inference implementation\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3759111e-04 5.1659691e-01 6.2522836e-14 1.4260615e-20 1.3898015e-10\n",
      " 4.8304182e-01 4.5237612e-11 6.0631383e-13 1.6117900e-20 2.2362331e-04]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
