{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import instrumentum\n",
    "\n",
    "import lightgbm as ltb\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from instrumentum.model_tuning.wrapper_optuna import OptunaSearchCV\n",
    "from instrumentum.model_tuning._optuna_dispatchers import optuna_param_disp\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify data paths\n",
    "dataset = 'out/gestures.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "random         1874\n",
       "hand_closed     673\n",
       "two_up          648\n",
       "hang_in         623\n",
       "hand_open       581\n",
       "victory         530\n",
       "call            525\n",
       "one_up          416\n",
       "machedici       414\n",
       "ok              409\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(dataset, header=None) \n",
    "\n",
    "y = data.iloc[:, 0]\n",
    "X = data.iloc[: , 1:]\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': 0,\n",
       " 'victory': 1,\n",
       " 'call': 2,\n",
       " 'hang_in': 3,\n",
       " 'one_up': 4,\n",
       " 'two_up': 5,\n",
       " 'hand_closed': 6,\n",
       " 'hand_open': 7,\n",
       " 'machedici': 8,\n",
       " 'random': 9}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = y.unique()\n",
    "classes = {classes[i]: i for i in range(len(classes))}\n",
    "\n",
    "y = y.map(classes)\n",
    "\n",
    "X = X.to_numpy().astype(np.float32)\n",
    "y = y.to_numpy().astype(np.float32)\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=RANDOM_SEED)\n",
    "# # y_train = y_train.reshape(len(y_train),1)\n",
    "# # y_test = y_test.reshape(len(y_test),1)\n",
    "# classes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/lightgbm/basic.py\", line 2605, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/lightgbm/basic.py\", line 1815, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/lightgbm/basic.py\", line 1538, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/lightgbm/basic.py\", line 1659, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Multiclass objective and metrics don't match\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "22-07-30 00:39 | INFO | Trials: 1, Best Score: nan, Score nan\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "[LightGBM] [Fatal] Multiclass objective and metrics don't match\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/lightgbm/basic.py\", line 2605, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/lightgbm/basic.py\", line 1815, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/lightgbm/basic.py\", line 1538, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/lightgbm/basic.py\", line 1659, in __init_from_np2d\n",
      "    _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Multiclass objective and metrics don't match\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No trials are completed yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/federico/codes/tf/02_trainer_othery.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/federico/codes/tf/02_trainer_othery.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m cv \u001b[39m=\u001b[39m RepeatedStratifiedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, n_repeats\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/federico/codes/tf/02_trainer_othery.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m os \u001b[39m=\u001b[39m OptunaSearchCV(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/federico/codes/tf/02_trainer_othery.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/federico/codes/tf/02_trainer_othery.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mroc_auc_ovo\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/federico/codes/tf/02_trainer_othery.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     n_iter\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/federico/codes/tf/02_trainer_othery.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/federico/codes/tf/02_trainer_othery.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m os\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/instrumentum/model_tuning/wrapper_optuna.py:68\u001b[0m, in \u001b[0;36mOptunaSearchCV.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     66\u001b[0m optuna\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mset_verbosity(optuna\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mERROR)\n\u001b[1;32m     67\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m study\u001b[39m.\u001b[39;49moptimize(\n\u001b[1;32m     69\u001b[0m     \u001b[39mlambda\u001b[39;49;00m trial: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_opt_generic_objective(\n\u001b[1;32m     70\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m     71\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m     72\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m     73\u001b[0m         cv\u001b[39m=\u001b[39;49mcv_orig,\n\u001b[1;32m     74\u001b[0m         scoring\u001b[39m=\u001b[39;49mscorer,\n\u001b[1;32m     75\u001b[0m     ),\n\u001b[1;32m     76\u001b[0m     n_trials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter,\n\u001b[1;32m     77\u001b[0m )\n\u001b[1;32m     79\u001b[0m \u001b[39m# Let's set some values so the upper classes can work\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefit:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/optuna/study/study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mif\u001b[39;00m n_jobs \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    393\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    394\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    395\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis feature will be removed in v4.0.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    396\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    397\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m     )\n\u001b[0;32m--> 400\u001b[0m _optimize(\n\u001b[1;32m    401\u001b[0m     study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    402\u001b[0m     func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    403\u001b[0m     n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    404\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    405\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    406\u001b[0m     catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    407\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    408\u001b[0m     gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    409\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    410\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m show_progress_bar:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/optuna/study/_optimize.py:264\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch):\n\u001b[0;32m--> 264\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    265\u001b[0m \u001b[39mreturn\u001b[39;00m trial\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/optuna/study/_optimize.py:213\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    210\u001b[0m     thread\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    212\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m     value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/instrumentum/model_tuning/wrapper_optuna.py:69\u001b[0m, in \u001b[0;36mOptunaSearchCV.fit.<locals>.<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     66\u001b[0m optuna\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mset_verbosity(optuna\u001b[39m.\u001b[39mlogging\u001b[39m.\u001b[39mERROR)\n\u001b[1;32m     67\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m study\u001b[39m.\u001b[39moptimize(\n\u001b[0;32m---> 69\u001b[0m     \u001b[39mlambda\u001b[39;00m trial: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_opt_generic_objective(\n\u001b[1;32m     70\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m     71\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m     72\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m     73\u001b[0m         cv\u001b[39m=\u001b[39;49mcv_orig,\n\u001b[1;32m     74\u001b[0m         scoring\u001b[39m=\u001b[39;49mscorer,\n\u001b[1;32m     75\u001b[0m     ),\n\u001b[1;32m     76\u001b[0m     n_trials\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter,\n\u001b[1;32m     77\u001b[0m )\n\u001b[1;32m     79\u001b[0m \u001b[39m# Let's set some values so the upper classes can work\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefit:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/instrumentum/model_tuning/wrapper_optuna.py:121\u001b[0m, in \u001b[0;36mOptunaSearchCV._opt_generic_objective\u001b[0;34m(self, trial, X, y, cv, scoring)\u001b[0m\n\u001b[1;32m    114\u001b[0m score \u001b[39m=\u001b[39m cross_val_score(\n\u001b[1;32m    115\u001b[0m     candidate_estimator, X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, cv\u001b[39m=\u001b[39mcv, scoring\u001b[39m=\u001b[39mscoring\n\u001b[1;32m    116\u001b[0m )\u001b[39m.\u001b[39mmean()\n\u001b[1;32m    118\u001b[0m trial_n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(trial\u001b[39m.\u001b[39mstudy\u001b[39m.\u001b[39mtrials)\n\u001b[1;32m    119\u001b[0m best_score \u001b[39m=\u001b[39m (\n\u001b[1;32m    120\u001b[0m     score\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mif\u001b[39;00m trial_n \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m score \u001b[39m>\u001b[39m trial\u001b[39m.\u001b[39;49mstudy\u001b[39m.\u001b[39;49mbest_value\n\u001b[1;32m    122\u001b[0m     \u001b[39melse\u001b[39;00m trial\u001b[39m.\u001b[39mstudy\u001b[39m.\u001b[39mbest_value\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    125\u001b[0m logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    126\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mTrials: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, Best Score: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, Score \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, trial_n, best_score, score\n\u001b[1;32m    127\u001b[0m )\n\u001b[1;32m    128\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mParameters: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(param))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/optuna/study/study.py:74\u001b[0m, in \u001b[0;36mBaseStudy.best_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbest_value\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m     64\u001b[0m     \u001b[39m\"\"\"Return the best objective value in the study.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \n\u001b[1;32m     66\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39m            If the study has more than one direction.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     best_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_trial\u001b[39m.\u001b[39mvalue\n\u001b[1;32m     75\u001b[0m     \u001b[39massert\u001b[39;00m best_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m best_value\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/optuna/study/study.py:97\u001b[0m, in \u001b[0;36mBaseStudy.best_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_multi_objective():\n\u001b[1;32m     92\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     93\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m     )\n\u001b[0;32m---> 97\u001b[0m \u001b[39mreturn\u001b[39;00m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_storage\u001b[39m.\u001b[39;49mget_best_trial(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_study_id))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/optuna/storages/_in_memory.py:311\u001b[0m, in \u001b[0;36mInMemoryStorage.get_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    309\u001b[0m best_trial_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_studies[study_id]\u001b[39m.\u001b[39mbest_trial_id\n\u001b[1;32m    310\u001b[0m \u001b[39mif\u001b[39;00m best_trial_id \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo trials are completed yet.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    312\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_studies[study_id]\u001b[39m.\u001b[39mdirections) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    313\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    314\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBest trial can be obtained only for single-objective optimization.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    315\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
     ]
    }
   ],
   "source": [
    "estimator = ltb.LGBMClassifier()\n",
    "\n",
    "search_function = optuna_param_disp[estimator.__class__.__name__]\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2)\n",
    "\n",
    "os = OptunaSearchCV(\n",
    "    estimator=estimator,\n",
    "    scoring=\"roc_auc_ovo\",\n",
    "    cv=cv,\n",
    "    search_space=search_function,\n",
    "    n_iter=5,\n",
    ")\n",
    "os.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def _lgbmclassifier_default(trial: optuna.trial.Trial):\n",
    "    params = {\n",
    "        # \"verbosity\": -1,\n",
    "        \"boosting_type\": trial.suggest_categorical(\n",
    "            \"boosting_type\", [\"gbdt\", \"dart\", \"goss\"]\n",
    "        ),\n",
    "        \"verbose\": -1,\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 5, 500, step=5),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 15),\n",
    "        \"learning_rate\": trial.suggest_float(\n",
    "            \"learning_rate\", 1e-5, 1.0, log=True\n",
    "        ),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\n",
    "            \"colsample_bytree\", 0.0, 1.0\n",
    "        ),\n",
    "        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-3, 30),\n",
    "        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-3, 30),\n",
    "        \"min_split_gain\": trial.suggest_float(\"min_split_gain\", 0, 15),\n",
    "    }\n",
    "\n",
    "    return "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5de9ea968598f77146e9bcf7403aafc4990d0b8fd820669c1cc9c3a0b1879543"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
