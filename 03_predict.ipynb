{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[5384]: Class CaptureDelegate is implemented in both /opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/cv2/cv2.abi3.so (0x152ece480) and /opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/mediapipe/.dylibs/libopencv_videoio.3.4.16.dylib (0x1639f4860). One of the two will be used. Which one is undefined.\n",
      "objc[5384]: Class CVWindow is implemented in both /opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/cv2/cv2.abi3.so (0x152ece4d0) and /opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x16288ca68). One of the two will be used. Which one is undefined.\n",
      "objc[5384]: Class CVView is implemented in both /opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/cv2/cv2.abi3.so (0x152ece4f8) and /opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x16288ca90). One of the two will be used. Which one is undefined.\n",
      "objc[5384]: Class CVSlider is implemented in both /opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/cv2/cv2.abi3.so (0x152ece520) and /opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x16288cab8). One of the two will be used. Which one is undefined.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import imutils\n",
    "import pandas as pd\n",
    "from src.handDetector import HandDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ok',\n",
       " 1: 'victory',\n",
       " 2: 'call',\n",
       " 3: 'hang_in',\n",
       " 4: 'one_up',\n",
       " 5: 'two_up',\n",
       " 6: 'hand_closed',\n",
       " 7: 'hand_open',\n",
       " 8: 'machedici',\n",
       " 9: 'random'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get this info from the trainer's notebook\n",
    "classes = {\n",
    "    \"ok\": 0,\n",
    "    \"victory\": 1,\n",
    "    \"call\": 2,\n",
    "    \"hang_in\": 3,\n",
    "    \"one_up\": 4,\n",
    "    \"two_up\": 5,\n",
    "    \"hand_closed\": 6,\n",
    "    \"hand_open\": 7,\n",
    "    \"machedici\": 8,\n",
    "    \"random\": 9,\n",
    "}\n",
    "classes = {v: k for k, v in classes.items()}\n",
    "classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_text(img, text):\n",
    "\n",
    "  font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "  fontScale = 0.5\n",
    "  color = (255, 0, 0)\n",
    "  thickness=1\n",
    "\n",
    "  y0, dy = 15, 15\n",
    "  for i, line in enumerate(text):\n",
    "    y = y0 + i*dy\n",
    "    cv2.putText(img, line, (5, y ), font, fontScale, color, thickness, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_save_path = 'models/lite.hdf5'\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()\n",
    "def prediction(arr):\n",
    "\n",
    "  arr = arr.astype(np.float32)\n",
    "  # Get I / O tensor\n",
    "  input_details = interpreter.get_input_details()\n",
    "  output_details = interpreter.get_output_details()\n",
    "\n",
    "  interpreter.set_tensor(input_details[0]['index'], np.array([arr]))\n",
    "\n",
    "  interpreter.invoke()\n",
    "  tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "  sq = np.squeeze(tflite_results)\n",
    "  idx = np.argmax(sq)\n",
    "  pred = sq[idx]\n",
    "  return idx, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stuff to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.teams_interaction import TeamsInteractions\n",
    "\n",
    "teams = TeamsInteractions()\n",
    "\n",
    "def do_your_stuff(classes, idx_pred):\n",
    "\n",
    "\n",
    "    if classes[idx_pred] == \"call\":\n",
    "        teams.meet_call_click()\n",
    "\n",
    "    if classes[idx_pred] == \"ok\":\n",
    "        teams.meet_send_reaction_click(\"ok\")\n",
    "\n",
    "    if classes[idx_pred] == \"hand_open\":\n",
    "        teams.meet_send_reaction_click(\"raisehand\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found button on screen: meet_unmute.png\n",
      "Not found button on screen: meet_unmute.png\n",
      "Not found button on screen: meet_unmute.png\n",
      "Not found button on screen: meet_unmute.png\n",
      "          Display Type: Built-In Retina LCD\n",
      "          Resolution: 2560 x 1600 Retina\n",
      "Not found button on screen: meet_unmute.png\n",
      "          Display Type: Built-In Retina LCD\n",
      "          Resolution: 2560 x 1600 Retina\n",
      "Not found button on screen: meet_unmute.png\n",
      "Not found button on screen: meet_unmute.png\n",
      "Not found button on screen: meet_unmute.png\n",
      "Not found button on screen: meet_unmute.png\n",
      "Not found button on screen: meet_unmute.png\n",
      "          Display Type: Built-In Retina LCD\n",
      "          Resolution: 2560 x 1600 Retina\n",
      "Not found button on screen: meet_mute.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ESC_KEY = 27\n",
    "WAIT_KEY = 30\n",
    "MIN_SCORE = 0.8\n",
    "\n",
    "detector = HandDetector()\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "      break\n",
    "\n",
    "    k = cv2.waitKey(WAIT_KEY)\n",
    "    if k == ESC_KEY:\n",
    "      break\n",
    "\n",
    "    img = imutils.resize(img, width=800)\n",
    "   \n",
    "\n",
    "    detector.fit(img)\n",
    "    img = detector.transform_draw(img)\n",
    "    img = detector.transform_connect_lines(img)\n",
    "    img = detector.transform_square(img)\n",
    "\n",
    "    if detector.found_hands():\n",
    "      arr = detector.get_positions_normalized()[0]\n",
    "      idx_pred, pred = prediction(arr)\n",
    "\n",
    "      if pred >= MIN_SCORE and classes[idx_pred] != \"random\":\n",
    "        put_text(img, [str(classes[idx_pred]), str(pred)])\n",
    "\n",
    "        do_your_stuff(classes, idx_pred)\n",
    "\n",
    "   \n",
    "    cv2.imshow(\"Image\", img)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ok',\n",
       " 1: 'victory',\n",
       " 2: 'call',\n",
       " 3: 'hang_in',\n",
       " 4: 'one_up',\n",
       " 5: 'two_up',\n",
       " 6: 'hand_closed',\n",
       " 7: 'hand_open',\n",
       " 8: 'machedici',\n",
       " 9: 'random'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5de9ea968598f77146e9bcf7403aafc4990d0b8fd820669c1cc9c3a0b1879543"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
