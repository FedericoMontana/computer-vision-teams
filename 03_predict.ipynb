{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[4834]: Class CaptureDelegate is implemented in both /opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/cv2/cv2.abi3.so (0x169476480) and /opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/mediapipe/.dylibs/libopencv_videoio.3.4.16.dylib (0x295308860). One of the two will be used. Which one is undefined.\n",
      "objc[4834]: Class CVWindow is implemented in both /opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/cv2/cv2.abi3.so (0x1694764d0) and /opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x2950dca68). One of the two will be used. Which one is undefined.\n",
      "objc[4834]: Class CVView is implemented in both /opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/cv2/cv2.abi3.so (0x1694764f8) and /opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x2950dca90). One of the two will be used. Which one is undefined.\n",
      "objc[4834]: Class CVSlider is implemented in both /opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/cv2/cv2.abi3.so (0x169476520) and /opt/homebrew/Caskroom/miniforge/base/envs/env_tf/lib/python3.8/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x2950dcab8). One of the two will be used. Which one is undefined.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import imutils\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "\n",
    "from src.hands_finder import HandsFinder\n",
    "from src.video_utils import VideoCapture, add_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ok',\n",
       " 1: 'victory',\n",
       " 2: 'call',\n",
       " 3: 'hang_in',\n",
       " 4: 'one_up',\n",
       " 5: 'two_up',\n",
       " 6: 'hand_closed',\n",
       " 7: 'hand_open',\n",
       " 8: 'machedici',\n",
       " 9: 'random',\n",
       " 10: 'fuck you'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get this info from the trainer's notebook\n",
    "classes = {\n",
    "    \"ok\": 0,\n",
    "    \"victory\": 1,\n",
    "    \"call\": 2,\n",
    "    \"hang_in\": 3,\n",
    "    \"one_up\": 4,\n",
    "    \"two_up\": 5,\n",
    "    \"hand_closed\": 6,\n",
    "    \"hand_open\": 7,\n",
    "    \"machedici\": 8,\n",
    "    \"random\": 9,\n",
    "    \"fuck you\": 10,\n",
    "}\n",
    "classes = {v: k for k, v in classes.items()}\n",
    "classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightgbm\n",
    "model_save_path = 'models/classifier.joblib'\n",
    "clf = load(model_save_path) \n",
    "\n",
    "def prediction(arr):\n",
    "\n",
    "  arr = arr.astype(np.float32)\n",
    "  arr = arr.reshape(1, -1).round(4)\n",
    "  predict_result = clf.predict_proba(arr)\n",
    "\n",
    "  sq = np.squeeze(predict_result)\n",
    "  idx = np.argmax(sq)\n",
    "  pred = sq[idx]\n",
    "  return idx, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "tflite_save_path = 'models/lite.hdf5'\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()\n",
    "def prediction(arr):\n",
    "\n",
    "  arr = arr.astype(np.float32)\n",
    "  # Get I / O tensor\n",
    "  input_details = interpreter.get_input_details()\n",
    "  output_details = interpreter.get_output_details()\n",
    "\n",
    "  interpreter.set_tensor(input_details[0]['index'], np.array([arr]))\n",
    "\n",
    "  interpreter.invoke()\n",
    "  tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "  sq = np.squeeze(tflite_results)\n",
    "  idx = np.argmax(sq)\n",
    "  pred = sq[idx]\n",
    "  return idx, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stuff to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.teams_interaction import TeamsInteractions\n",
    "\n",
    "teams = TeamsInteractions(use_keys_when_possible=False)\n",
    "\n",
    "def do_your_stuff(classes, idx_pred):\n",
    "\n",
    "\n",
    "    if classes[idx_pred] == \"call\":\n",
    "        teams.meet_call_click()\n",
    "\n",
    "    if classes[idx_pred] == \"ok\":\n",
    "        teams.meet_send_reaction_click(\"ok\")\n",
    "\n",
    "    if classes[idx_pred] == \"hand_open\":\n",
    "        teams.meet_send_reaction_click(\"raisehand\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found button on screen: meet_unmute.png\n",
      "Not found button on screen: meet_unmute.png\n",
      "Not found button on screen: meet_unmute.png\n",
      "          Display Type: Built-In Retina LCD\n",
      "          Resolution: 2560 x 1600 Retina\n",
      "          Display Type: Built-In Retina LCD\n",
      "          Resolution: 2560 x 1600 Retina\n",
      "          Display Type: Built-In Retina LCD\n",
      "          Resolution: 2560 x 1600 Retina\n",
      "          Display Type: Built-In Retina LCD\n",
      "          Resolution: 2560 x 1600 Retina\n",
      "          Display Type: Built-In Retina LCD\n",
      "          Resolution: 2560 x 1600 Retina\n",
      "          Display Type: Built-In Retina LCD\n",
      "          Resolution: 2560 x 1600 Retina\n",
      "          Display Type: Built-In Retina LCD\n",
      "          Resolution: 2560 x 1600 Retina\n",
      "          Display Type: Built-In Retina LCD\n",
      "          Resolution: 2560 x 1600 Retina\n",
      "          Display Type: Built-In Retina LCD\n",
      "          Resolution: 2560 x 1600 Retina\n",
      "Not found button on screen: meet_open_reactions.png\n",
      "Not found button on screen: meet_unmute.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MIN_SCORE = 0.9\n",
    "\n",
    "detector = HandsFinder()\n",
    "vc = VideoCapture(fps=10)\n",
    "\n",
    "\n",
    "CONTINUITY = 3\n",
    "history_gestures = [None] * CONTINUITY\n",
    "mod = -1\n",
    "\n",
    "while vc.take_next():\n",
    "\n",
    "\n",
    "    img = vc.get_frame()\n",
    "   \n",
    "    mod = 0 if (mod == CONTINUITY - 1) else mod + 1\n",
    "    history_gestures[mod] = None # by default\n",
    "\n",
    "    detector.fit(img)\n",
    "    img = detector.transform_draw(img)\n",
    "    img = detector.transform_connect_lines(img)\n",
    "    img = detector.transform_square(img)\n",
    "\n",
    "    if detector.found_hands():\n",
    "      arr = detector.get_positions_normalized()[0]\n",
    "      idx_pred, pred = prediction(arr)\n",
    "      class_pred = classes[idx_pred]\n",
    "\n",
    "      if pred >= MIN_SCORE and class_pred != \"random\":\n",
    "        history_gestures[mod] = class_pred\n",
    "\n",
    "        # Do I have the full history with the same gesture?\n",
    "        if len(set(history_gestures)) == 1:\n",
    "          add_texts(img, [str(classes[idx_pred]), str(pred)])\n",
    "\n",
    "        do_your_stuff(classes, idx_pred)\n",
    "\n",
    "    \n",
    "    cv2.imshow(\"Image\", img)\n",
    "\n",
    "vc.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5de9ea968598f77146e9bcf7403aafc4990d0b8fd820669c1cc9c3a0b1879543"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
